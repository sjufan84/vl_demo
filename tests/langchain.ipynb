{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Using Langchain to upload documentation to a Pinecone index:\n",
    "\n",
    "# Initial Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import openai\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY2\")\n",
    "openai.organization = os.getenv(\"OPENAI_ORG2\")\n",
    "\n",
    "pinecone_key = os.getenv(\"PINECONE_KEY\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "anthropic = Anthropic(api_key=os.getenv(\"ANTHROPIC_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"first_rule3.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First Rule\\n'\n",
      " '1\\n'\n",
      " 'CONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, '\n",
      " 'trade-secret \\n'\n",
      " 'information and is shared only with the understanding that you will not '\n",
      " 'share its contents or ideas with \\n'\n",
      " 'third parties without the express written consent of the plan '\n",
      " 'author.Executive Summary\\n'\n",
      " 'Opportunity\\n'\n",
      " 'Problem\\n'\n",
      " 'Vocal technology is advancing rapidly, but protections for artists have '\n",
      " 'lagged \\n'\n",
      " 'behind. There are currently few regulations preventing unauthorized vocal \\n'\n",
      " \"replication or ensuring fair compensation when an artist's voiceprint is \"\n",
      " 'used. First \\n'\n",
      " 'Rule seeks to empower singers by giving them full control over if, when, and '\n",
      " 'how \\n'\n",
      " 'their voice is used. More specifically, control over consent, credit, '\n",
      " 'compensation, \\n'\n",
      " 'creation, and collaboration.\\n'\n",
      " 'Our platform solves three key problems facing artists today:\\n'\n",
      " '1.Deepfake Risks: Artificial intelligence can now create synthetic media, \\n'\n",
      " 'including audio, that manipulates or generates content to make it appear \\n'\n",
      " 'real. Unregulated use of this technology poses serious risks for singers, \\n'\n",
      " \"whose voice and likeness could be misused without their consent. Rule 1's \\n\"\n",
      " 'voiceprint protection helps artists maintain control over their identity '\n",
      " 'and \\n'\n",
      " 'brand.\\n'\n",
      " '2.Future Lack of Monetization Options: Currently, artists have limited ways '\n",
      " 'to \\n'\n",
      " \"generate revenue from their voiceprints and little say in how it's used by \\n\"\n",
      " 'others. First Rule opens up new secure monetization streams, enabling \\n'\n",
      " 'singers to profit directly from authorized use of their voiceprint along '\n",
      " 'with \\n'\n",
      " 'other downstream opportunities such as boutique LLMs trained on their \\n'\n",
      " \"catalog's data if and when they decide to open up to that revenue stream.\\n\"\n",
      " '3.Legal Complications: Ownership and usage rights surrounding vocals are \\n'\n",
      " 'complex, often leading to costly legal disputes over royalties, licensing, '\n",
      " 'and \\n'\n",
      " 'intellectual property. First Rule provides a transparent framework for '\n",
      " 'artists \\n'\n",
      " 'to authorize use of their voiceprint, set clear terms and conditions, and \\n'\n",
      " 'ensure fair compensation - reducing headaches for both singers and \\n'\n",
      " 'producers.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(pages[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "tiktoken_len(\"hello I am a chunk of text and using the tiktoken_len function \"\n",
    "             \"we can find the length of this chunk of text in tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiktoken_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sjufa\\OneDrive\\Desktop\\Current Projects\\vl_demo\\tests\\langchain.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     chunk_size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     chunk_overlap\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     length_function\u001b[39m=\u001b[39mtiktoken_len,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     separators\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tiktoken_len' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"first_rule.pdf\")\n",
    "pages = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='CONFIDENTIAL\\nRULE 1\\nYour Voice, Your Signature, Your Legacy\\nBusiness Plan\\nPrepared October 2023\\nContact Information\\nJoel Kaiser\\nvocalockr@gmail.com\\n5714656108\\nwww.vocalockr.com' metadata={'source': 'first_rule3.pdf', 'page': 0}\n",
      "page_content=\"First Rule\\n1\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Executive Summary\\nOpportunity\\nProblem\\nVocal technology is advancing rapidly, but protections for artists have lagged \\nbehind. There are currently few regulations preventing unauthorized vocal \\nreplication or ensuring fair compensation when an artist's voiceprint is used. First \\nRule seeks to empower singers by giving them full control over if, when, and how \\ntheir voice is used. More specifically, control over consent, credit, compensation, \\ncreation, and collaboration.\\nOur platform solves three key problems facing artists today:\\n1.Deepfake Risks: Artificial intelligence can now create synthetic media, \\nincluding audio, that manipulates or generates content to make it appear \\nreal. Unregulated use of this technology poses serious risks for singers, \\nwhose voice and likeness could be misused without their consent. Rule 1's \\nvoiceprint protection helps artists maintain control over their identity and \\nbrand.\\n2.Future Lack of Monetization Options: Currently, artists have limited ways to \\ngenerate revenue from their voiceprints and little say in how it's used by \\nothers. First Rule opens up new secure monetization streams, enabling \\nsingers to profit directly from authorized use of their voiceprint along with \\nother downstream opportunities such as boutique LLMs trained on their \\ncatalog's data if and when they decide to open up to that revenue stream.\\n3.Legal Complications: Ownership and usage rights surrounding vocals are \\ncomplex, often leading to costly legal disputes over royalties, licensing, and \\nintellectual property. First Rule provides a transparent framework for artists \\nto authorize use of their voiceprint, set clear terms and conditions, and \\nensure fair compensation - reducing headaches for both singers and \\nproducers.\" metadata={'source': 'first_rule3.pdf', 'page': 1}\n",
      "page_content=\"First Rule\\n2\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.By solving these key problems, First Rule gives singers unprecedented control, \\nconnection, and commercial opportunity. Our platform is designed specifically with \\nestablished artists in mind, focusing on empowerment over ownership. While big \\ntech races to gain control of artists' brands, First Rule puts the power back where it \\nbelongs - in the artists' hands.\\nSolution\\nAt First Rule, we offer artists the opportunity to protect their melodic voiceprints \\nby securely storing their voiceprint data and granting access to it through the \\nissuance of NFTs. This not only includes traditional contracts between artists and \\ntheir labels, but also opens up new and unique avenues for monetizing their voice \\nthrough AI-powered content generation and model training. By entrusting their \\nmelodic voiceprints to us, artists can effortlessly grant licenses for a wide range of \\npotential use cases, while having the peace of mind of easily identifying copyright \\ninfringement and misuse. They can confidently track which parties they have \\nauthorized for specific use cases, ensuring their voiceprints are used appropriately.\\nMarket\\nFirst Rule focuses on pop, country, hip hop, R&B, and electronic music artists based \\nin the United States. To be eligible to use Rule 1, an artist must have:\\n• A minimum of 250,000 ( flexible number ) followers across streaming \\nplatforms (e.g. Spotify, Apple Music) and social media (e.g. Instagram, \\nTwitter)\\n• 1-5 million streams of at least one of their singles in the past 12-24 months\\nThese parameters ensure we are working with established and fast-growing artists \\nwho have an engaged fan base and the potential for mainstream success. By \\nfocusing on these popular, English-language based genres and geographies, we can \\nscale quickly to reach a large portion of engaged music consumers and the \\ninfluencers that shape their tastes.\" metadata={'source': 'first_rule3.pdf', 'page': 2}\n",
      "page_content=\"First Rule\\n3\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Competition\\n1. Mint Songs: A blockchain-based platform for artists to mint and distribute \\nunique songs as NFTs, earning crypto rewards.\\n2. Elf.Tech: Grimes collaborates with TuneCore and CreateSafe for AI-driven \\nmusic production, allowing users to transform their own singing recordings \\ninto Grimes' voice.\\n3. Controlla.XYZ: A music platform connecting artists with fans, providing \\nmonetization opportunities and building a loyal fan base.\\n4. Voice-Swap.AI: Easily transform your vocals to match the style of chart-\\ntopping singers.\\n5. Google + Universal Records, Warner Records: They announced (but haven't \\nreleased) a label-first/top-down approach to a similar product as First Rule.\\n6. Kits.AI by Arpeggi Labs: Generate your own AI voices in one click, or \\ntransform your voice using our growing library of officially licensed AI voices. \\nUnfortunately, Kits.AI has multiple stripped and illegally cloned voices in \\ntheir library + very few known artists in the approved and licensable \\nvoiceprint library.\\nWhy Us?\\nWhile several companies are racing to capitalize on the emerging trend of AI \\ncontent generation using vocal cloning and generative voice (vocaloid) \\ntechnologies, First Rule takes a unique approach by prioritizing the artists. We \\nfirmly believe in giving artists complete autonomy to determine when, where, and \\nhow to license their voices.\\nAt First Rule, artists retain ownership of the contracts that govern the deployment \\nof their Melodic Voices (MV) as non-fungible tokens (NFTs). This ownership \\nempowers them to make decisions on their own terms, ensuring that their artistic \\nvision is respected.\\nMoreover, First Rule possesses extensive industry knowledge and strong \\nconnections. Our headquarters are strategically located in Nashville, TN, which is \\nthe heart of the music world. This proximity enables us to forge relationships with a\" metadata={'source': 'first_rule3.pdf', 'page': 3}\n",
      "page_content='First Rule\\n4\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.wide range of artists, industry insiders, studios, and labels who share our vision for \\nthe future of AI music generation and protection.\\nExpectations\\nForecast\\nIn December 2023, we anticipate that our revenue will begin to flow from various \\nsources. This includes the income generated from onboarding and initiation costs, \\nas well as the proceeds from percentages of artist-issued melodic voiceprint and AI \\nCo-Writer NFTs + licensing agreements.\\nOur projection for October is to onboard 10 artists, resulting in approximately \\n$15,000 in initiation fees. Following this, we anticipate a monthly subscription fee of \\n$1,000 for each artist. Moreover, we anticipate that roughly 50% of our artists will \\nexpress interest in our boutique model training program, which entails an initiation \\nfee of $1,500 and a 5% profit structure per subscription.\\nInitially, we estimate that each artist will generate $5,000 in revenue per month. \\nHowever, this figure is expected to increase to $10,000 per artist per month as we \\nachieve a remarkable 200% growth in our artist clientele starting from October \\n2023.' metadata={'source': 'first_rule3.pdf', 'page': 4}\n",
      "page_content=\"First Rule\\n5\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Financial Highlights by Year\\nFinancing Needed\\nOur goal is to secure $500K at a $4M pre-money valuation in a pre-seed round \\nwhich will be matched by an agile software development team which has offered \\nthat + scaling our prototype to a sellable product. From there, we'll enter a seed \\nround where we'll aim for a rollup deal which will involve acquiring two music tech \\nstartups that have already developed and launched their products. By leveraging \\ntheir existing technology, we aim to accelerate our growth and scale rapidly.\\nSpecifically in the near term we need financing for the following -- \\n1) Outreach to potential artist partners to shepherd us through our initial rollout\\n2) Specialized blockchain, AI, and front end engineers to blitz scale the product and \\nbring all the features, particularly the voiceprint NFTs and the boutique models to \\nmarket.\\n3) In addition to engineering needs, we will need legal advisors to help us navigate \\nthe potential legal issues surrounding artist protection and label relationships.\" metadata={'source': 'first_rule3.pdf', 'page': 5}\n",
      "page_content='First Rule\\n6\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.4)  We will need core administrative, technical, marketing, and sales support as well \\nas liaisons with potential mergers and roll-ups that we want to initiate as soon as \\npossible.\\n5) For a clearer idea of the near and longer term projected expenditures, reference \\nthe detailed profit and loss metrics included in this plan.' metadata={'source': 'first_rule3.pdf', 'page': 6}\n",
      "page_content=\"First Rule\\n7\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Opportunity\\nProblem & Solution\\nProblem Worth Solving\\nProblem Worth Solving\\nBrief: The 4 C’s of Control are not in the Artist's hands when it comes to Creativity \\n& Collaboration:\\n1. Compensation\\n2. Credit\\n3. Consent\\nThis is how First Rule solves for that:\\n1. Inefficiencies in Licensing and Monetizing Vocal Talents: The music industry \\ncurrently faces a cumbersome and often opaque process when it comes to \\nlicensing vocal talents. The lack of standardized systems often leads to legal \\nconflicts, delays, and missed opportunities for both artists and those seeking to \\nutilize their talents. First Rule introduces a streamlined platform where artists' \\nvoices are represented through Melodic Voiceprint NFTs, allowing for transparent \\nand efficient licensing.\\n2. Lack of Control and Security over Vocal Intellectual Property: Artists often find \\nthemselves at the mercy of various intermediaries and platforms that control the \\ndistribution and monetization of their vocal work. First Rule's model provides a \\ndecentralized and secure method of controlling one's vocal IP. The physical USB \\nkeys for cold storage, along with secure backup options, empower artists to have \\ngreater autonomy and security over their work.\\n3. Limited Customization and Integration with Existing Platforms: Traditional \\nmethods of generating and distributing vocal content are siloed and lack flexibility. \\nRule 1's proposed integration with other platforms, like EastWest Sounds' vocal \\nsample libraries, will enable secure unique and boutique artist model generations.\" metadata={'source': 'first_rule3.pdf', 'page': 7}\n",
      "page_content='First Rule\\n8\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.This allows for a more versatile and tailored experience, expanding the range of \\npossibilities in content creation.\\n4. Barrier to Innovative Content Generation: Creating personalized content like a \\nfamous singer\\'s rendition of \"Happy Birthday\" is an ambitious idea that is often \\nhindered by legal complexities and technological limitations. First Rule\\'s innovation \\nbreaks down these barriers by utilizing MV-NFTs to facilitate new content creation \\nin a lawful and efficient manner.\\n5. Need for Strategic Onboarding of Artists: Artists require proper representation \\nand incentives to embrace new technologies. First Rule\\'s strategic approach to \\nonboarding, including physical Artist\\'s Vault Intro Packages and engaging well-\\nknown brand ambassadors, ensures a smooth transition and promotes adoption \\nwithin the artistic community.\\nIn summary, First Rule is not just a product; it\\'s a holistic solution addressing \\nseveral key challenges within the music industry (and beyond). By modernizing \\nlicensing processes, enhancing security, fostering integration, promoting new \\ncontent creation, and thoughtfully engaging with artists, we\\'re building a platform \\nthat resonates with the current needs of the industry and paves the way for future \\ninnovation. Our approach sets us apart from traditional and competitive solutions \\nand marks an exciting advancement in how vocal talents are utilized, protected, \\nand celebrated.\\nOur Solution\\nIn our quest to address the significant challenges faced by artists, we present a \\nunique end-to-end solution that involves leveraging AI and blockchain technology \\nto enable them to generate and securely store their melodic voiceprints . By doing \\nso, they will have the power to open up downstream opportunities by minting NFTs \\nthat serve as exclusive contracts, granting them full autonomy and control. \\nAdditionally, we aim to simplify the process of developing personalized trained LLM \\nmodels called \"Co-writer\", thereby unlocking unprecedented at-scale revenue \\nopportunities for artists. This innovative approach not only safeguards their vocal \\nidentity but also amplifies their engagement with fans and fellow musicians, \\nfostering novel and exhilarating connections.' metadata={'source': 'first_rule3.pdf', 'page': 8}\n",
      "page_content='First Rule\\n9\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Target Market\\nMarket Size\\nThe global music industry generates over $50 billion in revenue annually. Within \\nthis market, the licensing and monetization of vocal assets from famous singers is a \\nfast-growing segment. According to Music Business Worldwide, over the past three \\nyears, the number of brands seeking to license music and vocals from well-known \\nartists has increased by 63%. Similarly, the demand for customized vocal content, \\nsuch as personal messages or re-recorded songs, has risen by a staggering 137% \\nover the same period.\\nFirst Rule is poised to capitalize on the momentum in this segment by providing \\nfamous singers an exclusive and innovative platform to license, share, and monetize \\ntheir voiceprint/vocal assets. We make the process more efficient, secure, and \\npersonalized for both the artists and those integrating and engaging with the \\nvocals. Our model gives singers more control and creative freedom over their work \\nwhile opening up new revenue streams from licensing, customized content, and \\nother opportunities.\\nTarget Segments\\nFirst Rule has identified two key customer segments: famous singers (clients) and \\nvocal asset integrators/fans (users).\\nFamous Singers (Clients)\\nThis segment includes well-known recording artists, particularly those with a \\nunique vocal style or brand. They stand to gain the most from our platform by \\nlicensing and monetizing their vocals on their terms. We aim to onboard 50 major \\nartists in our first year, adding 25-50 more each subsequent year.\\nVocal Asset Integrators/Fans (Users)\\nThis broad segment includes music producers, interactive media companies, \\nbrands, and fans seeking to license, integrate or engage with vocals from famous' metadata={'source': 'first_rule3.pdf', 'page': 9}\n",
      "page_content='First Rule\\n10\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.singers. Whether for commercial or personal use, First Rule provides the means for \\nusers to easily access and work with celebrity vocals. We anticipate growing this \\nsegment to over 100 million users within 5 years based on current industry trends.\\nBy targeting these segments, First Rule is poised to dominate an untapped space in \\nthe music technology market. We have developed key partnerships and \\nintegrations to reach clients and users, setting the groundwork for rapid expansion \\nand massive scale. The vast size of the music industry and increasing demand for \\nvocal assets point to nearly limitless potential. First Rule is the innovative solution \\nthe world has been waiting for.\\nCompetition\\nCurrent Alternatives\\nControlla.XYZ allows fans to interact with and remix songs from their favorite \\nartists. While an innovative concept, Controlla.XYZ does not enable new revenue \\nstreams from those assets.\\nElf.Tech utilizes AI to transform users’ voices into the style of popular artists like \\nGrimes. However, Elf.Tech does not provide a platform for artists to share, \\nmonetize, or gain insights from their vocal assets. The technology is limited to \\nimpersonating established artists’ voices rather than enabling new creative works \\nfrom artists’ actual vocal assets.\\nVoice-Swap.AI also relies on AI to swap users’ voices for those of popular singers. \\nLike Elf.Tech, Voice-Swap.AI does not work with artists’ own vocal assets or \\nsupport artists in building new revenue streams and fan connections from those \\nassets. The platforms are more focused on vocal impersonation than empowering \\nartists with control over their creative works.\\nMint Songs allows artists to sell songs as NFTs, providing some control over \\ndistribution and earning potential. However, Mint Songs does not specifically \\nfocus on vocal assets, provide a platform for sharing and monetizing those assets, \\nor generate insights from their use. While an interesting concept for song' metadata={'source': 'first_rule3.pdf', 'page': 10}\n",
      "page_content=\"First Rule\\n11\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.ownership and distribution, Mint Songs lacks First Rule's comprehensive solution \\ncentered on amplifying the value and impact of artists’ vocal creativity.\\nKits.AI allows you to generate your own AI voices in one click, or transform your \\nvoice using our growing library of officially licensed AI voices, yet some of their \\nlibrary's user-created voiceprints are illegally ripped voiceprints, clearly \\nindicating a lack of security even though they boast being on-chain.\\nIn contrast, First Rule provides an all-in-one exclusive platform for artists to \\nupload, protect, share, and monetize their vocal assets. First Rule's solution \\ngenerates insights into how those assets are being used to build connections \\nbetween artists and voiceprint-integrators and fans. With this innovative approach \\nfocused specifically on vocal assets + our proprietary Co-Writer tool, First Rule \\noffers artists greater control, ownership and earning potential from their \\ncreative works. \\nOur Advantages\\nFirst Rule's Key Advantages:\\n1.Innovation in Personalization: First Rule's use of Melodic Voiceprint NFTs \\n(MV-NFTs) allows artists to write dynamic lyrics with AI co-writers, a truly \\nunique and cutting-edge service that blends AI and creativity.\\n2.Revenue Enhancement: By leveraging famous artists' melodic voiceprints \\nalong with their AI Co-Writer, emerging artists can achieve significant \\nrevenue growth, as evidenced by successful collaborations. This value \\nproposition extends beyond mere creativity, driving tangible financial \\nresults. We see an opportunity for artists to capture and generate novel \\nrevenue streams where they previously have lost revenue to copy-cats. \\nImitators will inevitably rip off great artists' sound and style without even \\nstealing their inspiration's voiceprint, but now artists will be able to more \\ndirectly profit off of this common occurrence.\\n3.Targeting Established Artists: Focusing on famous singers as primary \\nadopters positions First Rule in a niche market with a significant influence on \\ntrends and public opinion. This strategic focus on key influencers can lead to \\nwider market penetration.\" metadata={'source': 'first_rule3.pdf', 'page': 11}\n",
      "page_content=\"First Rule\\n12\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.4.Integration and Collaboration: By partnering with integration points like \\nEastWest Sounds' vocal sample libraries and other content generation \\navenues, First Rule offers a comprehensive and unique ecosystem for music \\ncreation. This integration sets First Rule apart from competitors who may \\noffer isolated or fragmented solutions.\\n5.Cold Storage Solutions for Security: Offering physical USB key charges for \\ncold storage adds a layer of security for artists' wallets. This attention to \\nsecurity could be a unique selling point in a market concerned with digital \\nasset protection.\\n6.Tailored Solutions: First Rule offerings are not one-size-fits-all. From \\nboutique artist model generations to specific song content generation, these \\nsolutions are highly customizable, catering to the unique needs and \\naspirations of individual artists.\\n7.Strategic Acquisitions: With plans for roll-ups like Controlla.XYZ and \\nEmvoice, First Rule demonstrates an aggressive growth strategy that aims to \\nrapidly scale and consolidate key technologies and market positions.\\nConclusion:\\nFirst Rule's competitive edge lies in its exclusivity, innovation, targeted approach, \\nintegration, and commitment to delivering real value to both established and \\neventually, emerging artists. These advantages position First Rule as a unique \\nplayer in the market, offering specialized solutions that are designed to enhance \\ncreativity, secure digital assets, and drive revenue growth for its users. The \\ncompany's strategy, technology, and vision align to create a strong value \\nproposition that sets it apart from other competitors in the field.\" metadata={'source': 'first_rule3.pdf', 'page': 12}\n",
      "page_content='First Rule\\n13\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Execution\\nMarketing & Sales\\nMarketing Plan\\nFirst Rule will leverage an integrated marketing strategy to drive brand awareness \\nand customer acquisition. Our approach focuses on digital advertising, social media \\noutreach, search engine optimization, email marketing, influencer collaborations, \\nand strategic partnerships.\\nWe will invest in targeted online ads across music-focused platforms to reach key \\naudiences, including artists, producers, and industry leaders. By optimizing ad \\ncontent and placements, we aim to generate interest and drive traffic to our \\nwebsite and social media profiles.\\nOur social media profiles on Instagram, Twitter, and LinkedIn will feature regular \\nposts with insights, updates, and content that resonate with the music community \\nat large. By posting daily and engaging actively with our followers, we will establish \\nFirst Rule as an authority and standard in our industry.\\nOptimizing our website for search engines like Google will increase our visibility in \\norganic search results for relevant keywords. We will also develop and distribute \\neducational content, including blog posts, videos, and downloadable resources. \\nThis content will improve SEO and provide value to our target customers.\\nThrough regular email newsletters, we will keep subscribers up to date with \\ncompany news, platform updates, resources, and success stories from customers. \\nNewsletters will increase brand recall and give recipients a reason to re-engage \\nwith our website and social media profiles.\\nCollaborating with 25 music artists and producers as official brand ambassadors \\nwill amplify our marketing reach. These influencers will promote First Rule to their \\nfollowers across social media and at industry events. In exchange, we will provide \\nthem with access to our platform and promotional opportunities.' metadata={'source': 'first_rule3.pdf', 'page': 13}\n",
      "page_content=\"First Rule\\n14\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.First Rule’s unique logo and visual identity will give us a professional, polished \\nbrand image while Artist Vault's custom brand, which will be developed with \\nBrother's Design Co. and possibly Luum Studios will embody our secure and \\nprotective platform and overall ecosystem. We'll apply this branding consistently \\nacross all marketing materials and digital presences to build brand recognition.\\nSelf-selection will be a major focus of our tiered marketing campaigns; Basic, \\nPremium, and Platinum tier subscription options to Artist Vault will be \\naccompanied by short thumbnails that play out the ideal customer using that tier's \\noffered services. \\nWith a strategy focused on resonating with our target customers through multiple \\ntouchpoints, First Rule is poised to become a leader in the music industry. By \\ndelivering real value to artists, businesses, and other music professionals, we will \\nachieve sustainable growth and success.\\nSales Plan\\nFor First Rule, the sales process is deeply entwined with providing value and \\nensuring customer satisfaction at each touch point. Our primary focus is on \\ntargeted B2B sales with famous singers initially. Here's how we plan to turn \\nprospects into paying customers:\\n1.Lead Qualification: Once an artist shows interest, our Business Development \\nteam will qualify the lead by assessing their needs and how First Rule can \\nspecifically address them.\\n2.Product Demo: The next step would be to arrange a product demonstration \\nwhere we can showcase our technology and its benefits in real-time. This \\nwill be a tailor-made presentation, focusing on how First Rule can help them \\nsecure their vocal signatures, train & create lyric-writing AI models ( Co-\\nWriter ), and issue melodic voiceprint NFTs.\\n3.Custom Proposal: After the demo, a custom proposal will be sent, which will \\ninclude a pricing model that best suits the artist's needs. We'll make it \\nflexible to accommodate the different revenue streams that artists have.\" metadata={'source': 'first_rule3.pdf', 'page': 14}\n",
      "page_content=\"First Rule\\n15\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.4.Onboarding and Training: Once the artist agrees to the proposal, we will \\nprovide comprehensive onboarding and training to help them get the most \\nout of First Rule.\\n5.Account Management: Each artist will have a dedicated account manager \\nwho will be responsible for nurturing the relationship, ensuring customer \\nsatisfaction, and exploring upsell or cross-sell opportunities.\\n6.Closing and Follow-Up: The deal is considered closed when the artist starts \\nusing First Rule for their work. We will continually follow up to gather \\nfeedback and make any necessary improvements.\\n7.Customer Success Team: This team will work on maximizing customer \\nlifetime value, monitoring artist engagement with First Rule, and proactively \\nidentifying any issues that could lead to churn.\\nStaffing Needs:\\n• Business Development Team for lead qualification and initial reach-out\\n• Account Managers for maintaining relationships\\n• Customer Success Team for post-sales activities\\nCommission Structure: We will operate on a tiered commission structure, \\nrewarding those who meet or exceed quotas.\\nSales Activities:\\n•Networking at industry-specific events:\\n• Attend music industry conferences like SXSW, Midem, and AIMM Con \\nto connect with artists, producers, labels, and managers.\\n• Host sponsored stages, panels, or networking events at major music \\nfestivals to increase brand visibility.\\n• Leverage existing relationships with influencers to gain introductions \\nto new prospects.\\n•Engaging with referrals:\\n• Offer referral bonuses to incentivize existing customers to connect us \\nwith artists in their network.\\n• Send personalized outreach to referred prospects that highlights the \\nreferring customer's positive experience.\" metadata={'source': 'first_rule3.pdf', 'page': 15}\n",
      "page_content=\"First Rule\\n16\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.• Prioritize referred leads during lead qualification since they come pre-\\nvetted.\\n•Existing customer follow-ups for upsell or cross-sell opportunities:\\n• Check in regularly to gauge satisfaction and explore additional needs \\nwe can fulfill.\\n• Educate on new features or products that could augment their usage.\\n• Offer special bundled pricing or discounts for existing customers \\nadding services.\\n•Thought leadership through webinars, articles, etc., to establish First Rule \\nas an industry innovator:\\n• Host webinars showcasing First Rule's capabilities to prospects.\\n• Publish bylined articles in music industry trade publications.\\n• Speak at industry conferences about AI-enabled content creation and \\nIP protection.\\n• Promote thought leadership content through owned channels and \\nsocial media.\\nWe're well-equipped to build and maintain a robust sales pipeline and ensure a high \\nconversion rate of prospects into satisfied, paying customers.\\nOperations\\nLocations & Facilities\\nCurrently, First Rule is based in Nashville, TN, and operates in a decentralized \\nmanner with all team members working remotely.  Our vision is to establish a \\npresence in the vibrant Music City by making use of shared office spaces. These \\nspaces will not only provide cold storage options for our clients but also offer a \\nflexible workspace where our staff can periodically gather to collaborate as a \\ncohesive team.\" metadata={'source': 'first_rule3.pdf', 'page': 16}\n",
      "page_content=\"First Rule\\n17\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Technology\\nIn our current phase, we are focused on building a demo product that combines a \\nStreamlit UI and a pythonic backend. This initial version will serve as a foundation \\nfor the future development of a full-stack application that can support both web \\nand mobile platforms. Our ultimate goal is to create a comprehensive platform that \\nseamlessly integrates robust AI model training capabilities with the power of \\nBlockchain technology and music studio software.\\nEquipment & Tools\\nWe currently operate using our local machines, but as we expand, it is essential for \\nus to have a reliable source of GPU processors. These processors can be either \\nphysical or, more likely, cloud-based, to facilitate the training and maintenance of \\nour AI models. Additionally, we will need a secure solution for storing our partner \\nartists' private blockchain keys in cold storage. Furthermore, we will require cloud \\nstorage for the melodic voiceprints themselves to ensure their accessibility and \\nprotection.\" metadata={'source': 'first_rule3.pdf', 'page': 17}\n",
      "page_content=\"First Rule\\n18\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Milestones & Metrics\\nMilestones Table\\nMilestone Due Date Who's Responsible Details\\nFunctional demo \\ncompletedCompleted Dave T Functional demo \\ncompleted, ready to shop \\nto potential partner \\nartists and ready to scale \\nas new engineers are \\nbrought on.\\nNew leadership \\nonboarded.Completed Flex C-Suite exec, CFO / \\nCOO onboarded to assist \\nwith rapid scaling.\\nPre-seed Financing \\nSecuredOctober 25, 2023 Founding Team Initial larger round of \\nfinancing to secure the \\ncapital for rapid \\nexpansion and execution \\nof our plan to blitz-scale.\\nInitial Artist Partners \\nOnboardedNovember 15, 2023 Founding Team Initial partner artists / \\nevangelists secured, scout \\nand marketing teams in \\nplace for artist outreach \\nand communication.\\nTeam members \\nonboardedNovember 15, 2023 Advisors and investor \\nrelations exec onboarded \\nto explore.\\nCTO and engineering \\nteam build outNovember 30, 2023 As we scale, more \\nengineering talent and \\noversight will be critical, \\nthus requiring new team \\nmembers to be \\nonboarded.\" metadata={'source': 'first_rule3.pdf', 'page': 18}\n",
      "page_content='First Rule\\n19\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Launch and Initial \\nAdoptionDecember 11, 2023 - Launch the Artist Vault™ \\nplatform with early-bird \\npromotions for artists to \\nupload voiceprints. \\n- Partner with 5-10 \\nemerging artists for \\nexclusive Co-Writer™ \\ntraining sessions and/or \\ncontests.\\nBoutique Models Training \\nBegins, MV and NFTs \\nrolled outJanuary 01, 2024 CTO Once the initial artists \\nhave been secured, we \\nwill begin boutique model \\ntraining and enhanced \\nblockchain MV protection \\nprotocols.\\nExpansion within Music \\nIndustryFebruary 26, 2024 - Grow user base: Launch \\nNorth American marketing \\ncampaigns targeting \\nindependent artists. \\n     - $5K/mo on PR\\n- Introduce new features \\nin the Artist Vault, such \\nas advanced analytics for \\nartists to track voiceprint \\nusage.\\nExit [Scenario 1] November 28, 2025 - Acquisition by a larger \\nmusic or tech company, \\npossibly Nvidia, with \\nwhom we already have \\nconnections.\\n- Licensing the technology \\nfor use in other \\nindustries.' metadata={'source': 'first_rule3.pdf', 'page': 19}\n",
      "page_content='First Rule\\n20\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Exit [Scenario 2] February 23, 2026 - Strategic partnership or \\nacquisition with a major \\nentertainment company; \\nPossibly a PRO\\nExit [Scenario 3] December 01, 2027 - IPO\\nKey Metrics\\nAt First Rule, we have established the following key performance indicators (KPIs) \\nto track our progress:\\nArtist Vault Acquisitions:\\nOur goal is to onboard 500 artists in our first year who complete voiceprint \\nregistration and upload samples to their Artist Vault. This metric indicates market \\ntraction for our core value proposition.\\nSubscription Conversion Rate:\\nWe aim for a 10% conversion rate from platform visitors to paying subscribers of \\nour Full Studio Access service. This will validate product-market fit.\\nUser Engagement:\\nWe will track the frequency of Co-Writer interactions and satisfaction ratings. Our \\ntarget is an average of 2 sessions per week with 75% user satisfaction.\\nCash Reserves:\\nMaintaining reserves equal to 6 months of operating costs allows us to withstand \\nmarket fluctuations and invest in R&D.\\nCustomer Retention:' metadata={'source': 'first_rule3.pdf', 'page': 20}\n",
      "page_content='First Rule\\n21\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Keeping churn below 2% per month indicates our customers find ongoing value in \\nour platform.\\nBy monitoring these metrics, we can course-correct and optimize our go-to-\\nmarket strategy. Our success hinges on driving value for artists and fans.' metadata={'source': 'first_rule3.pdf', 'page': 21}\n",
      "page_content=\"First Rule\\n22\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Company\\nOverview\\nFirst Rule is a DBA for SpokeTek, Inc, a Delaware C-Corp. Rule 1 is owned by Joel \\nRobert Kaiser, Dave S. Thomas, and Robert Baker.\\nTeam\\nManagement Team\\nDave S. Thomas  - Co-Founder | CTO/Chief Magic Officer\\nSkills and Experience: Dave brings a wealth of experience in tech entrepreneurship \\nand innovation. He has a strong background in music technology, having worked on \\ncutting-edge projects that bridge the gap between art and technology.\\nRole: Dave will focus on strategic leadership, technology vision, and operational \\nguidance. His in-depth industry knowledge and innovative mindset will drive the \\nproduct development and growth strategy.\\nStrengths: His blend of technical expertise and creative thinking makes him a \\ndriving force behind First Rule's unique value proposition.\\nJoel Robert Kaiser  - Co-Founder | Co-CEO\\nSkills and Experience: Joel has a diversified background in business management, \\ndesign, branding, marketing, and the entertainment industry. He has worked with \\nnumerous artists and has a keen understanding of the music business landscape.\\nRole: Joel will oversee marketing, artist relations, and business expansion. His \\nhands-on experience with artist management will guide the development of tools \\ntailored to the needs of famous singers.\\nStrengths: Joel's strong network and deep insight into the music industry position \\nhim as a critical player in navigating the intricate dynamics of the music world.\" metadata={'source': 'first_rule3.pdf', 'page': 22}\n",
      "page_content=\"First Rule\\n23\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Rob Baker  - Co-Founder | Co-CEO\\nSkills and Experience: Rob is a two-decade veteran of the music industry in \\nNashville, with almost 12 years as an entertainment attorney and another 12 as an \\nartist manager. After practicing corporate law at Waller, Lansden, Dortch and \\nDavis, Rob became the managing partner of his own firm and led a practice that \\nincluded multi-platinum artists, writers, producers, executives, independent record \\nlabels and music publishers before establishing and chairing the entertainment \\ngroup at Bone, McAllester, Norton.  In 2011, Rob shifted gears, began managing \\nartists full-time and grew Longshot Management into a successful boutique \\nmanagement company, whose artists boasted multiple number 1 songs and albums, \\nmulti-million dollar tours and partnerships and took home CMA, ACM, CMT, BMI \\nand ASCAP awards.\\nRole: Rob will provide seasoned leadership and utilize his extensive network of \\nexecutives, artists, writers, producers and service providers in the entertainment \\nindustry to onboard artists, writers and users to scale the growth of First Rule.\\nStrengths: Extensive experience and relationships as a trusted advisor in the music \\nand entertainment industry.  Rob has founded and led two successful companies \\nfrom inception to high profitability.\\nConclusion\\nThe First Rule management team is a well-rounded blend of skills and expertise, \\nuniquely positioned to capitalize on this market opportunity. Their combined \\nexperience in technology, music, legal affairs, and business development equips \\nthem to navigate the complexities of this innovative venture. The synergy among \\nthe team members amplifies First Rule's strengths, positioning the company as a \\nleader in transforming how vocal assets are managed and experienced in the music \\nindustry.\\nAdvisors\\nLarry Bridegsmith  - AI & Blockchain Advisor\" metadata={'source': 'first_rule3.pdf', 'page': 23}\n",
      "page_content=\"First Rule\\n24\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Skills and Experience: Larry is an expert in artificial intelligence, blockchain \\ntechnology, and legal affairs. His experience spans multiple successful projects \\ninvolving complex technological solutions and legal structures.\\nRole: Larry's advisory role focuses on ensuring that First Rule's technology is \\ncutting-edge, secure, and compliant with legal regulations. He guides the \\nintegration of AI and blockchain into Rule 1's offerings.\\nStrengths: His blend of technological know-how and legal acumen is instrumental \\nin building a robust, trustworthy platform.\\n \\nTaylor Cason  - Business Development and Industry Relations Advisor\\nSkills and Experience: Taylor has an extensive background in business \\ndevelopment and has strong ties within the music industry. She has experience in \\nforging successful collaborations and identifying growth opportunities.\\nRole: Taylor will focus on cultivating industry relationships, identifying strategic \\npartners, and steering business development efforts to ensure First Rule's growth \\nand market penetration.\\nStrengths: Taylor's knack for relationship-building and keen business acumen \\nmake her pivotal in expanding First Rule's reach and influence.\" metadata={'source': 'first_rule3.pdf', 'page': 24}\n",
      "page_content=\"First Rule\\n25\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Financial Plan\\nForecast\\nKey Assumptions\\nFirst Rule's projected revenue and operating costs have been developed based on \\nthe following key assumptions:\\nRevenue Streams\\n• Melodic Voiceprint NFT (MV-NFT) Contracts: We estimate these licenses to \\ngenerate substantial revenue, reflecting a % fee on each MV-NFT issued and \\nlicensed out.\\n• Initiation and Management Fees: Recurring revenue will come from initial \\nonboarding and ongoing profile management fees for artists.\\n• Physical USB Key Sales: Revenue will be generated from sales of secure \\nphysical storage keys for MV-NFTs, appealing to security-conscious artists.\\n• Content Creation and Integrations: Partnerships to develop artist avatars and \\ncontent, e.g. a 'Happy Birthday' track using famous artists' melodic \\nvoiceprints, will open new revenue channels.\\n• Boutique LLMs trained on singers', singer-songwriters', and songwriters' \\ncatalog data = Co-Writer  AI model\\nGrowth Assumptions\\nWe anticipate gradual growth given the newness of our offering and the need to \\nbuild trust. Focusing first on well-known artists will drive further adoption.\\nMajor Expenses \\n• Brand Ambassador Acquisition: Pop-ups backstage at award shows, festivals \\nand other trade events will build awareness and help in acquiring early \\nadopters after we launch our beta version and open our pilot program. \\n• Developing and delivering pass codes (physically and electronically) to \\n250 initial adopters for exclusive functional demos of our platform.\" metadata={'source': 'first_rule3.pdf', 'page': 25}\n",
      "page_content=\"First Rule\\n26\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.• Staffing: Engineers, support, executives, and marketers will make up a \\nsubstantial part of operating expenses.\\n• Acquisitions: The purchases of Controlla.XYZ, Emvoice, and Suno.AI should \\nbe viewed as key strategic investments.\\nProfit Expectations\\nWe expect profitability to correlate with platform adoption, backing our brand \\nmessaging of being the new industry standard, and development of native and \\ndownstream marketing opportunities. Conservatively, we forecast running at a loss \\nfor 18–24 months, but with an aim to generate revenue as early as December of \\n2023.\\nIn summary, First Rule's projections indicate an innovative, opportunity-rich \\nventure poised for strategic growth. Aligning with industry trends and addressing \\nunmet needs positions us uniquely. Continuous revenue streams and one-off \\nopportunities create balance, supported by investment in ambassadorship and \\ntalent.\\nWhile challenging, First Rule's originality and fit with the current art and tech \\nlandscape make it a promising investment. Projections match trends and endorse a \\nmodel that resonates with stakeholders.\" metadata={'source': 'first_rule3.pdf', 'page': 26}\n",
      "page_content='First Rule\\n27\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Revenue by Month\\nExpenses by Month' metadata={'source': 'first_rule3.pdf', 'page': 27}\n",
      "page_content=\"First Rule\\n28\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Net Profit (or Loss) by Year\\nFinancing\\nUse of Funds\\nFirst Rule's Utilization of $500K in a Pre-seed Round with a Valuation of $4M\\nDescription: We will invest in research and development of our Beta versions of-\\n• Securing / creating voiceprints\\n• Integrating blockchain technology\\n• Reverse-audio search for natively comparing deepfakes to the vector of our \\nartists' voiceprints  \\n• Developing an API for scraping the entire internet for AI-generated \\nvoiceprint deepfakes\\n• Development of the Melodic Voiceprint NFT contracts \\n• Visual certification \\n• Green check mark\\n• On-chain certification\" metadata={'source': 'first_rule3.pdf', 'page': 28}\n",
      "page_content=\"First Rule\\n29\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.• Authentication measures for artists' profiles\\n• Boutique training of AI Co-Writer LLMs \\n• Multimodal collaborative interactions \\n• Text-to-Speech\\n• Speech-to-Speech\\n• Music-to-Music\\nBenefit: This investment will enhance and innovate our product offerings, with the \\ngoal of having industry-leading technology, security, and scalability.\\n \\nSeed round of $5M-$6M USD Raised:\\nDescription: We will invest in research and development of scalable versions of \\nBeta version\\nProduct Development and Technology Integration ($1.5M-$2M):\\n• Development of AiLias for artists \\n• End-user utilized Co-Writer masters owned entirely by artist(s)\\n• Secure plugin for DAWs (Digital Audio Workstations)\\nMarketing and Brand Ambassador Program ($800K-$1M):\\nDescription: We will expand our marketing efforts, including the introduction of \\nArtist's Vault Intro Packages and engagement with 100 key brand ambassadors. \\nContent marketing and artist-led contests will engage fan bases and other famous-\\ntier singers through these partnerships. Eventually, we'll also begin marketing to a \\nseparate market via a separate division; rising / aspiring artist users.\\nBenefit: This initiative will increase brand awareness, stimulate adoption among \\nartists, and contribute to the growth of our customer base.\\nPersonnel and Talent Acquisition ($800K-$1M):\\nDescription: We will hire key roles such as engineers, support staff, C-suite \\nexecutives, and marketers.\" metadata={'source': 'first_rule3.pdf', 'page': 29}\n",
      "page_content=\"First Rule\\n30\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Benefit: Building a talented team will enable us to execute our vision, provide \\nexcellent customer support, and drive growth.\\nOperational Expenses and Scaling ($400K-$600K):\\nDescription: These funds will cover the costs of daily operations, legal and \\ncompliance requirements, office space, and other essential functions.\\nBenefit: This allocation will support smooth and sustainable growth, ensuring that \\nour foundation is strong as we scale.\\nCapital Expenditures and Infrastructure ($300K-$400K):\\nDescription: We will invest in critical equipment, technology infrastructure, and \\nany necessary physical assets.\\nBenefit: This investment will ensure the stability, performance, and resilience of our \\nplatform and services.\\nContingency and Future Opportunities ($200K-$400K):\\nDescription: We will maintain a reserve for unforeseen expenses or strategic \\nopportunities that may arise.\\nBenefit: This allocation will provide us with financial flexibility and risk mitigation.\\nConclusion:\\nFirst Rule's strategic allocation of the raised funds is designed to fuel our vision, \\nenable blitz scaling, and build a robust and innovative platform in the music \\nindustry. By investing in acquisitions, technology, marketing, talent, and \\ninfrastructure, we aim to position First Rule as a leader in the space and deliver \\nvalue to both our customers and investors. Our approach is not only aligned with \\nour mission but also carefully crafted to drive revenue growth, increase market \\nshare, and maximize return on investment for our stakeholders.\" metadata={'source': 'first_rule3.pdf', 'page': 30}\n",
      "page_content=\"First Rule\\n31\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Sources of Funds\\nFirst Rule is seeking an initial pre-seed round of $500K to launch and scale our \\nplatform. This will be matched by our technical partners who will contribute an \\nadditional $250K along with their expertise building scalable AI and blockchain \\nplatforms. We have applied for an additional $250K from InvestTN's Regional Seed \\nFund which combined with the matching funds would fully capitalize our initial \\npre-seed needs.\\nOur pre-seed round will enable us to build an initial functioning platform to \\nmigrate our early beta users onto and complete further core technology \\ndevelopment. We will use this to establish product-market fit and prepare for a \\nfollow-on seed round of $5M to $6M to rapidly scale up the platform and user base \\nglobally.\\nFirst Rule is committed to a lean startup approach. Our pre-seed raise is prudently \\nsized to prove core assumptions before raising larger rounds. We have assembled \\nan experienced team that has repeatedly built startups frugally to profitability prior \\nto exit. Our matching technical partners share this experience scaling startups on a \\nbudget.\\nBeyond investment, our team and partners contribute significant sweat equity. We \\nwill remain disciplined in our spending and operations to maximize the impact of \\nfunds raised. Investments will focus on technology and reaching initial core \\nmilestones to set up a successful seed round.\" metadata={'source': 'first_rule3.pdf', 'page': 31}\n",
      "page_content='First Rule\\n32\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Statements\\nProjected Profit and Loss\\n2023 2024 2025 2026 2027\\nRevenue $785,593 $5,749,001 $31,509,745 $120,100,286\\nDirect Costs $1,500 $157,750 $40,000 $80,000 $160,000\\nGross Margin ($1,500) $627,843 $5,709,001 $31,429,745 $119,940,286\\nGross Margin % 80% 99% 100% 100%\\nOperating \\nExpenses\\nSalaries & \\nWages$27,500 $1,289,500 $2,389,000 $3,969,000 $5,019,000\\nEmployee \\nRelated \\nExpenses$5,500 $169,900 $341,800 $637,800 $837,800\\nDues and \\nSubscriptions$500 $6,500 $15,000 $25,000 $35,000\\nLegal Fees $119,000 $250,000 $350,000 $500,000\\nAccounting Fees $34,000 $50,000 $75,000 $100,000\\nLiability \\nInsurance$12,000 $25,000 $40,000 $60,000\\nSecurity $50,000 $75,000 $100,000\\nTravel $2,250 $34,000 $45,000 $75,000 $100,000\\nMeals and \\nEntertainment$3,750 $122,000 $200,000 $225,000 $250,000\\nUtilities $550 $6,850 $7,500 $12,500 $15,000\\nTelecommunica\\ntions$7,250 $10,000 $15,000 $20,000\\nOffice Supplies $600 $9,750 $12,000 $25,000 $25,000\\nLicensing\\nAdvertising and \\nPromotion$107,500 $250,000 $500,000 $750,000' metadata={'source': 'first_rule3.pdf', 'page': 32}\n",
      "page_content='First Rule\\n33\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Business \\nInsurance$250 $3,000 $5,000 $10,000 $25,000\\nSoftware \\nSubscriptions$375 $3,775 $5,000 $10,000 $25,000\\nSocial Media \\nMarketing \\n(Content \\nMarketing)$500 $18,250 $30,000 $50,000 $75,000\\nWebsite Hosting $50 $825 $1,500 $2,500 $3,500\\nCloud Storage \\nFees$788 $7,500 $37,500 $90,000\\nEquipment \\nRentals$12,250 $25,000 $50,000 $75,000\\nSecurity \\nSystems\\nMiscellaneous \\nOperating \\nExpenses$500 $22,500 $50,000 $75,000 $125,000\\nInternet Access $100 $2,150 $5,000 $7,500 $10,000\\nBank Service \\nCharges$368 $3,750 $19,500 $48,000\\nPrinting and \\nReproduction$75 $10,600 $15,000 $20,000 $20,000\\nTotal Operating \\nExpenses$42,500 $1,992,755 $3,793,050 $6,306,300 $8,308,300\\nOperating \\nIncome($44,000) ($1,364,912) $1,915,951 $25,123,445 $111,631,986\\nInterest Incurred\\nDepreciation and \\nAmortization\\nGain or Loss from \\nSale of Assets\\nIncome Taxes $0 $0 $139,436 $6,908,947 $30,698,796\\nTotal Expenses $44,000 $2,150,505 $3,972,486 $13,295,247 $39,167,096\\nNet Profit ($44,000) ($1,364,912) $1,776,515 $18,214,498 $80,933,190' metadata={'source': 'first_rule3.pdf', 'page': 33}\n",
      "page_content='First Rule\\n34\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Net Profit / \\nSales(174%) 31% 58% 67%' metadata={'source': 'first_rule3.pdf', 'page': 34}\n",
      "page_content='First Rule\\n35\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Projected Balance Sheet\\nStarting \\nBalances2023 2024 2025 2026 2027\\nCash $458,575 ($902,001) $969,259 $20,643,753 $106,674,438\\nAccounts \\nReceivable$0 $28,639 $83,703 $434,782 $1,603,120\\nInventory\\nOther Current \\nAssets\\nTotal Current \\nAssets$458,575 ($873,362) $1,052,962 $21,078,535 $108,277,558\\nLong-Term \\nAssets\\nAccumulated \\nDepreciation\\nTotal Long-\\nTerm Assets\\nTotal Assets $458,575 ($873,362) $1,052,962 $21,078,535 $108,277,558\\nAccounts \\nPayable$2,575 $35,550 $45,924 $74,146 $108,812\\nIncome Taxes \\nPayable$0 $0 $139,436 $1,922,288 $8,153,455\\nSales Taxes \\nPayable$0 $0 $0 $0\\nShort-Term \\nDebt\\nPrepaid \\nRevenue$0 $0 $0 $0 $0\\nTotal Current \\nLiabilities$0 $2,575 $35,550 $185,360 $1,996,434 $8,262,267\\nLong-Term Debt\\nLong-Term \\nLiabilities' metadata={'source': 'first_rule3.pdf', 'page': 35}\n",
      "page_content=\"First Rule\\n36\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Total \\nLiabilities$0 $2,575 $35,550 $185,360 $1,996,434 $8,262,267\\nPaid-In Capital $500,000 $500,000 $500,000 $500,000 $500,000\\nRetained \\nEarnings$0 $0 ($44,000) ($1,408,912) $367,603 $18,582,101\\nEarnings ($44,000) ($1,364,912) $1,776,515 $18,214,498 $80,933,190\\nTotal Owner's \\nEquity$0 $456,000 ($908,912) $867,603 $19,082,101 $100,015,291\\nTotal \\nLiabilities & \\nEquity$0 $458,575 ($873,362) $1,052,962 $21,078,535 $108,277,558\" metadata={'source': 'first_rule3.pdf', 'page': 36}\n",
      "page_content='First Rule\\n37\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Projected Cash Flow Statement\\n2023 2024 2025 2026 2027\\nNet Cash Flow \\nfrom Operations\\nNet Profit ($44,000) ($1,364,912) $1,776,515 $18,214,498 $80,933,190\\nDepreciation & \\nAmortization\\nChange in \\nAccounts \\nReceivable$0 ($28,639) ($55,064) ($351,079) ($1,168,338)\\nChange in \\nInventory\\nChange in \\nAccounts \\nPayable$2,575 $32,975 $10,374 $28,223 $34,666\\nChange in \\nIncome Tax \\nPayable$0 $0 $139,436 $1,782,852 $6,231,167\\nChange in Sales \\nTax Payable$0 $0 $0 $0\\nChange in \\nPrepaid \\nRevenue$0 $0 $0 $0 $0\\nNet Cash Flow \\nfrom Operations($41,425) ($1,360,576) $1,871,260 $19,674,494 $86,030,686\\nInvesting & \\nFinancing\\nAssets \\nPurchased or \\nSold\\nNet Cash from \\nInvesting\\nInvestments \\nReceived$500,000\\nDividends & \\nDistributions' metadata={'source': 'first_rule3.pdf', 'page': 37}\n",
      "page_content='First Rule\\n38\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Change in \\nShort-Term \\nDebt\\nChange in Long-\\nTerm Debt\\nNet Cash from \\nFinancing$500,000\\nCash at Beginning \\nof Period$0 $458,575 ($902,001) $969,259 $20,643,753\\nNet Change in Cash $458,575 ($1,360,576) $1,871,260 $19,674,494 $86,030,686\\nCash at End of \\nPeriod$458,575 ($902,001) $969,259 $20,643,753 $106,674,438' metadata={'source': 'first_rule3.pdf', 'page': 38}\n",
      "page_content=\"First Rule\\n39\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Appendix\\nProfit and Loss Statement (With Monthly Detail)\\n2023 Jan '23 Feb '23 Mar '23 Apr '23 May '23 June '23 July '23 Aug '23 Sept '23 Oct '23 Nov '23 Dec '23\\nTotal Revenue\\nTotal Direct \\nCosts$500 $500 $500\\nGross Margin ($500) ($500) ($500)\\nGross Margin %\\nOperating \\nExpenses\\nSalaries and \\nWages$13,000 $14,500\\nEmployee Related \\nExpenses$2,600 $2,900\\nDues and \\nSubscriptions$150 $150 $200\\nLegal Fees\\nAccounting Fees\\nLiability Insurance\\nSecurity\\nTravel $500 $750 $1,000\\nMeals and \\nEntertainment$1,000 $1,250 $1,500\\nUtilities $150 $200 $200\" metadata={'source': 'first_rule3.pdf', 'page': 39}\n",
      "page_content='First Rule\\n40\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Telecommunicatio\\nns\\nOffice Supplies $150 $150 $150 $150\\nLicensing\\nAdvertising and \\nPromotion\\nBusiness Insurance $250\\nSoftware \\nSubscriptions$50 $75 $100 $150\\nSocial Media \\nMarketing \\n(Content \\nMarketing)$500\\nWebsite Hosting $25 $25\\nCloud Storage \\nFees\\nEquipment \\nRentals\\nSecurity Systems\\nMiscellaneous \\nOperating \\nExpenses$500\\nInternet Access $100\\nBank Service \\nCharges\\nPrinting and \\nReproduction$75\\nTotal \\nOperating \\nExpenses$200 $2,025 $18,225 $22,050\\nOperating \\nIncome($200) ($2,525) ($18,725) ($22,550)\\nInterest Incurred' metadata={'source': 'first_rule3.pdf', 'page': 40}\n",
      "page_content='First Rule\\n41\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Depreciation and \\nAmortization\\nGain or Loss from \\nSale of Assets\\nIncome Taxes $0 $0 $0 $0\\nTotal Expenses $200 $2,525 $18,725 $22,550\\nNet Profit ($200) ($2,525) ($18,725) ($22,550)\\nNet Profit / \\nSales' metadata={'source': 'first_rule3.pdf', 'page': 41}\n",
      "page_content=\"First Rule\\n42\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.2024 Jan '24 Feb '24 Mar '24 Apr '24 May '24 June '24 July '24 Aug '24 Sept '24 Oct '24 Nov '24 Dec '24\\nTotal Revenue $18,625 $72,663 $84,240 $97,884 $153,853 $167,402 $190,927\\nTotal Direct \\nCosts$8,750 $9,000 $9,500 $11,000 $12,000 $13,000 $14,500 $15,000 $15,500 $16,000 $16,500 $17,000\\nGross Margin ($8,750) ($9,000) ($9,500) ($11,000) ($12,000) $5,625 $58,163 $69,240 $82,384 $137,853 $150,902 $173,927\\nGross Margin % 30% 80% 82% 84% 90% 90% 91%\\nOperating \\nExpenses\\nSalaries and \\nWages$34,000 $74,500 $87,000 $99,000 $100,000 $120,500 $121,500 $122,000 $122,500 $136,000 $136,000 $136,500\\nEmployee Related \\nExpenses$6,000 $7,100 $9,600 $12,000 $12,100 $16,200 $16,300 $16,400 $16,500 $19,200 $19,200 $19,300\\nDues and \\nSubscriptions$250 $300 $400 $500 $500 $500 $500 $650 $650 $750 $750 $750\\nLegal Fees $5,000 $6,500 $7,500 $7,500 $10,000 $10,000 $10,000 $10,000 $12,500 $12,500 $12,500 $15,000\\nAccounting Fees $1,500 $2,500 $2,500 $5,000 $5,000 $2,500 $2,500 $2,500 $2,500 $2,500 $2,500 $2,500\\nLiability Insurance $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000\\nSecurity\\nTravel $1,250 $1,500 $1,750 $2,250 $2,500 $2,750 $3,000 $3,250 $3,500 $3,750 $4,000 $4,500\\nMeals and \\nEntertainment$2,000 $2,500 $5,000 $5,000 $7,500 $10,000 $15,000 $15,000 $15,000 $15,000 $15,000 $15,000\\nUtilities $250 $250 $300 $350 $350 $400 $450 $500 $750 $1,000 $1,000 $1,250\\nTelecommunicatio\\nns$500 $500 $500 $500 $500 $500 $500 $750 $750 $750 $750 $750\\nOffice Supplies $250 $250 $500 $750 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000\\nLicensing\\nAdvertising and \\nPromotion$5,000 $5,000 $7,500 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000\\nBusiness Insurance $250 $250 $250 $250 $250 $250 $250 $250 $250 $250 $250 $250\" metadata={'source': 'first_rule3.pdf', 'page': 42}\n",
      "page_content='First Rule\\n43\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Software \\nSubscriptions$150 $175 $200 $225 $250 $275 $300 $350 $400 $450 $500 $500\\nSocial Media \\nMarketing \\n(Content \\nMarketing)$750 $750 $1,250 $1,250 $1,500 $1,500 $1,500 $1,750 $2,000 $2,000 $2,000 $2,000\\nWebsite Hosting $50 $50 $50 $75 $75 $75 $75 $75 $75 $75 $75 $75\\nCloud Storage \\nFees$50 $75 $75 $100 $150 $150 $188\\nEquipment \\nRentals$500 $500 $500 $750 $750 $750 $1,250 $1,250 $1,500 $1,500 $1,500 $1,500\\nSecurity Systems\\nMiscellaneous \\nOperating \\nExpenses$1,000 $1,000 $1,000 $1,500 $2,000 $2,000 $2,000 $2,000 $2,500 $2,500 $2,500 $2,500\\nInternet Access $100 $100 $100 $150 $150 $150 $200 $200 $250 $250 $250 $250\\nBank Service \\nCharges$15 $38 $38 $50 $70 $70 $88\\nPrinting and \\nReproduction$150 $150 $300 $500 $500 $750 $750 $1,000 $1,250 $1,500 $1,750 $2,000\\nTotal \\nOperating \\nExpenses$59,950 $104,875 $127,200 $148,550 $155,925 $181,165 $188,188 $190,038 $195,025 $212,195 $212,745 $216,900\\nOperating \\nIncome($68,700) ($113,875) ($136,700) ($159,550) ($167,925) ($175,540) ($130,025) ($120,798) ($112,641) ($74,342) ($61,843) ($42,973)\\nInterest Incurred\\nDepreciation and \\nAmortization\\nGain or Loss from \\nSale of Assets\\nIncome Taxes $0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0\\nTotal Expenses $68,700 $113,875 $136,700 $159,550 $167,925 $194,165 $202,688 $205,038 $210,525 $228,195 $229,245 $233,900' metadata={'source': 'first_rule3.pdf', 'page': 43}\n",
      "page_content='First Rule\\n44\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Net Profit ($68,700) ($113,875) ($136,700) ($159,550) ($167,925) ($175,540) ($130,025) ($120,798) ($112,641) ($74,342) ($61,843) ($42,973)\\nNet Profit / \\nSales(942%) (179%) (143%) (115%) (48%) (37%) (23%)' metadata={'source': 'first_rule3.pdf', 'page': 44}\n",
      "page_content='First Rule\\n45\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.2023 2024 2025 2026 2027\\nTotal Revenue $785,593 $5,749,001 $31,509,745 $120,100,286\\nTotal Direct Costs $1,500 $157,750 $40,000 $80,000 $160,000\\nGross Margin ($1,500) $627,843 $5,709,001 $31,429,745 $119,940,286\\nGross Margin % 80% 99% 100% 100%\\nOperating Expenses\\nSalaries and Wages $27,500 $1,289,500 $2,389,000 $3,969,000 $5,019,000\\nEmployee Related Expenses $5,500 $169,900 $341,800 $637,800 $837,800\\nDues and Subscriptions $500 $6,500 $15,000 $25,000 $35,000\\nLegal Fees $119,000 $250,000 $350,000 $500,000\\nAccounting Fees $34,000 $50,000 $75,000 $100,000\\nLiability Insurance $12,000 $25,000 $40,000 $60,000\\nSecurity $50,000 $75,000 $100,000\\nTravel $2,250 $34,000 $45,000 $75,000 $100,000\\nMeals and Entertainment $3,750 $122,000 $200,000 $225,000 $250,000\\nUtilities $550 $6,850 $7,500 $12,500 $15,000\\nTelecommunications $7,250 $10,000 $15,000 $20,000\\nOffice Supplies $600 $9,750 $12,000 $25,000 $25,000\\nLicensing\\nAdvertising and Promotion $107,500 $250,000 $500,000 $750,000\\nBusiness Insurance $250 $3,000 $5,000 $10,000 $25,000\\nSoftware Subscriptions $375 $3,775 $5,000 $10,000 $25,000\\nSocial Media Marketing (Content \\nMarketing)$500 $18,250 $30,000 $50,000 $75,000\\nWebsite Hosting $50 $825 $1,500 $2,500 $3,500' metadata={'source': 'first_rule3.pdf', 'page': 45}\n",
      "page_content='First Rule\\n46\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Cloud Storage Fees $788 $7,500 $37,500 $90,000\\nEquipment Rentals $12,250 $25,000 $50,000 $75,000\\nSecurity Systems\\nMiscellaneous Operating Expenses $500 $22,500 $50,000 $75,000 $125,000\\nInternet Access $100 $2,150 $5,000 $7,500 $10,000\\nBank Service Charges $368 $3,750 $19,500 $48,000\\nPrinting and Reproduction $75 $10,600 $15,000 $20,000 $20,000\\nTotal Operating Expenses $42,500 $1,992,755 $3,793,050 $6,306,300 $8,308,300\\nOperating Income ($44,000) ($1,364,912) $1,915,951 $25,123,445 $111,631,986\\nInterest Incurred\\nDepreciation and Amortization\\nGain or Loss from Sale of Assets\\nIncome Taxes $0 $0 $139,436 $6,908,947 $30,698,796\\nTotal Expenses $44,000 $2,150,505 $3,972,486 $13,295,247 $39,167,096\\nNet Profit ($44,000) ($1,364,912) $1,776,515 $18,214,498 $80,933,190\\nNet Profit / Sales (174%) 31% 58% 67%' metadata={'source': 'first_rule3.pdf', 'page': 46}\n",
      "page_content=\"First Rule\\n47\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Balance Sheet (With Monthly Detail)\\nStarting \\nBalancesJan '23 Feb '23 Mar '23 Apr '23 May '23 June '23 July '23 Aug '23 Sept '23 Oct '23 Nov '23 Dec '23\\nCash $0 $0 $0 $0 $0 $0 $0 $0 ($100) ($1,463) $480,113 $458,575\\nAccounts \\nReceivable$0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0\\nInventory\\nOther Current \\nAssets\\nTotal Current \\nAssets$0 $0 $0 $0 $0 $0 $0 $0 ($100) ($1,463) $480,113 $458,575\\nLong-Term \\nAssets\\nAccumulated \\nDepreciation\\nTotal Long-\\nTerm Assets\\nTotal Assets $0 $0 $0 $0 $0 $0 $0 $0 ($100) ($1,463) $480,113 $458,575\\nAccounts \\nPayable$100 $1,263 $1,563 $2,575\\nIncome Taxes \\nPayable$0 $0 $0 $0\\nSales Taxes \\nPayable\\nShort-Term Debt\\nPrepaid Revenue $0\\nTotal Current \\nLiabilities$0 $100 $1,263 $1,563 $2,575\\nLong-Term Debt\" metadata={'source': 'first_rule3.pdf', 'page': 47}\n",
      "page_content=\"First Rule\\n48\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Long-Term \\nLiabilities\\nTotal \\nLiabilities$0 $100 $1,263 $1,563 $2,575\\nPaid-In Capital $500,000 $500,000\\nRetained \\nEarnings$0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0\\nEarnings ($200) ($2,725) ($21,450) ($44,000)\\nTotal Owner's \\nEquity$0 $0 $0 $0 $0 $0 $0 $0 $0 ($200) ($2,725) $478,550 $456,000\\nTotal \\nLiabilities & \\nEquity$0 $0 $0 $0 $0 $0 $0 $0 $0 ($100) ($1,463) $480,113 $458,575\" metadata={'source': 'first_rule3.pdf', 'page': 48}\n",
      "page_content=\"First Rule\\n49\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.2024 Jan '24 Feb '24 Mar '24 Apr '24 May '24 June '24 July '24 Aug '24 Sept '24 Oct '24 Nov '24 Dec '24\\nCash $400,150 $288,063 $155,025 ($550) ($165,088) ($342,851) ($477,521) ($599,180) ($711,674) ($793,677) ($857,277) ($902,001)\\nAccounts \\nReceivable$0 $0 $0 $0 $0 $2,794 $10,899 $12,636 $14,683 $23,078 $25,110 $28,639\\nInventory\\nOther Current \\nAssets\\nTotal Current \\nAssets$400,150 $288,063 $155,025 ($550) ($165,088) ($340,058) ($466,621) ($586,544) ($696,991) ($770,599) ($832,166) ($873,362)\\nLong-Term Assets\\nAccumulated \\nDepreciation\\nTotal Long-\\nTerm Assets\\nTotal Assets $400,150 $288,063 $155,025 ($550) ($165,088) ($340,058) ($466,621) ($586,544) ($696,991) ($770,599) ($832,166) ($873,362)\\nAccounts Payable $12,850 $14,638 $18,300 $22,275 $25,663 $26,233 $29,694 $30,569 $32,763 $33,498 $33,773 $35,550\\nIncome Taxes \\nPayable$0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0\\nSales Taxes \\nPayable$0 $0 $0 $0 $0 $0 $0\\nShort-Term Debt\\nPrepaid Revenue $0 $0 $0 $0 $0 $0 $0\\nTotal Current \\nLiabilities$12,850 $14,638 $18,300 $22,275 $25,663 $26,233 $29,694 $30,569 $32,763 $33,498 $33,773 $35,550\\nLong-Term Debt\\nLong-Term \\nLiabilities\" metadata={'source': 'first_rule3.pdf', 'page': 49}\n",
      "page_content=\"First Rule\\n50\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Total \\nLiabilities$12,850 $14,638 $18,300 $22,275 $25,663 $26,233 $29,694 $30,569 $32,763 $33,498 $33,773 $35,550\\nPaid-In Capital $500,000 $500,000 $500,000 $500,000 $500,000 $500,000 $500,000 $500,000 $500,000 $500,000 $500,000 $500,000\\nRetained Earnings ($44,000) ($44,000) ($44,000) ($44,000) ($44,000) ($44,000) ($44,000) ($44,000) ($44,000) ($44,000) ($44,000) ($44,000)\\nEarnings ($68,700) ($182,575) ($319,275) ($478,825) ($646,750) ($822,290) ($952,315) ($1,073,113) ($1,185,754) ($1,260,096) ($1,321,939) ($1,364,912)\\nTotal Owner's \\nEquity$387,300 $273,425 $136,725 ($22,825) ($190,750) ($366,290) ($496,315) ($617,113) ($729,754) ($804,096) ($865,939) ($908,912)\\nTotal \\nLiabilities & \\nEquity$400,150 $288,063 $155,025 ($550) ($165,088) ($340,058) ($466,621) ($586,544) ($696,991) ($770,599) ($832,166) ($873,362)\" metadata={'source': 'first_rule3.pdf', 'page': 50}\n",
      "page_content=\"First Rule\\n51\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Starting Balances 2023 2024 2025 2026 2027\\nCash $458,575 ($902,001) $969,259 $20,643,753 $106,674,438\\nAccounts Receivable $0 $28,639 $83,703 $434,782 $1,603,120\\nInventory\\nOther Current Assets\\nTotal Current Assets $458,575 ($873,362) $1,052,962 $21,078,535 $108,277,558\\nLong-Term Assets\\nAccumulated Depreciation\\nTotal Long-Term Assets\\nTotal Assets $458,575 ($873,362) $1,052,962 $21,078,535 $108,277,558\\nAccounts Payable $2,575 $35,550 $45,924 $74,146 $108,812\\nIncome Taxes Payable $0 $0 $139,436 $1,922,288 $8,153,455\\nSales Taxes Payable $0 $0 $0 $0\\nShort-Term Debt\\nPrepaid Revenue $0 $0 $0 $0 $0\\nTotal Current Liabilities $0 $2,575 $35,550 $185,360 $1,996,434 $8,262,267\\nLong-Term Debt\\nLong-Term Liabilities\\nTotal Liabilities $0 $2,575 $35,550 $185,360 $1,996,434 $8,262,267\\nPaid-In Capital $500,000 $500,000 $500,000 $500,000 $500,000\\nRetained Earnings $0 $0 ($44,000) ($1,408,912) $367,603 $18,582,101\\nEarnings ($44,000) ($1,364,912) $1,776,515 $18,214,498 $80,933,190\\nTotal Owner's Equity $0 $456,000 ($908,912) $867,603 $19,082,101 $100,015,291\" metadata={'source': 'first_rule3.pdf', 'page': 51}\n",
      "page_content='First Rule\\n52\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Total Liabilities & Equity $0 $458,575 ($873,362) $1,052,962 $21,078,535 $108,277,558' metadata={'source': 'first_rule3.pdf', 'page': 52}\n",
      "page_content=\"First Rule\\n53\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Cash Flow Statement (With Monthly Detail)\\n2023 Jan '23 Feb '23 Mar '23 Apr '23 May '23 June '23 July '23 Aug '23 Sept '23 Oct '23 Nov '23 Dec '23\\nNet Cash Flow \\nfrom \\nOperations\\nNet Profit ($200) ($2,525) ($18,725) ($22,550)\\nDepreciation & \\nAmortization\\nChange in \\nAccounts \\nReceivable$0 $0\\nChange in \\nInventory\\nChange in \\nAccounts \\nPayable$100 $1,163 $300 $1,013\\nChange in \\nIncome Tax \\nPayable$0 $0 $0 $0\\nChange in Sales \\nTax Payable\\nChange in \\nPrepaid \\nRevenue$0\\nNet Cash Flow \\nfrom \\nOperations$0 $0 ($100) ($1,363) ($18,425) ($21,538)\\nInvesting & \\nFinancing\\nAssets \\nPurchased or \\nSold\\nNet Cash from \\nInvesting\" metadata={'source': 'first_rule3.pdf', 'page': 53}\n",
      "page_content='First Rule\\n54\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Investments \\nReceived$500,000\\nDividends & \\nDistributions\\nChange in \\nShort-Term \\nDebt\\nChange in \\nLong-Term \\nDebt\\nNet Cash from \\nFinancing$500,000\\nCash at Beginning \\nof Period$0 $0 $0 $0 $0 $0 $0 $0 $0 ($100) ($1,463) $480,113\\nNet Change in \\nCash$0 $0 ($100) ($1,363) $481,575 ($21,538)\\nCash at End of \\nPeriod$0 $0 $0 $0 $0 $0 $0 $0 ($100) ($1,463) $480,113 $458,575' metadata={'source': 'first_rule3.pdf', 'page': 54}\n",
      "page_content=\"First Rule\\n55\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.2024 Jan '24 Feb '24 Mar '24 Apr '24 May '24 June '24 July '24 Aug '24 Sept '24 Oct '24 Nov '24 Dec '24\\nNet Cash Flow \\nfrom \\nOperations\\nNet Profit ($68,700) ($113,875) ($136,700) ($159,550) ($167,925) ($175,540) ($130,025) ($120,798) ($112,641) ($74,342) ($61,843) ($42,973)\\nDepreciation & \\nAmortization\\nChange in \\nAccounts \\nReceivable($2,794) ($8,106) ($1,737) ($2,047) ($8,395) ($2,032) ($3,529)\\nChange in \\nInventory\\nChange in \\nAccounts \\nPayable$10,275 $1,788 $3,663 $3,975 $3,388 $570 $3,461 $875 $2,194 $735 $275 $1,778\\nChange in \\nIncome Tax \\nPayable$0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0 $0\\nChange in Sales \\nTax Payable$0 $0 $0 $0 $0 $0 $0\\nChange in \\nPrepaid \\nRevenue$0 $0 $0 $0 $0 $0 $0\\nNet Cash Flow \\nfrom \\nOperations($58,425) ($112,088) ($133,038) ($155,575) ($164,538) ($177,764) ($134,669) ($121,659) ($112,494) ($82,003) ($63,600) ($44,724)\\nInvesting & \\nFinancing\\nAssets \\nPurchased or \\nSold\\nNet Cash from \\nInvesting\\nInvestments \\nReceived\" metadata={'source': 'first_rule3.pdf', 'page': 55}\n",
      "page_content='First Rule\\n56\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.Dividends & \\nDistributions\\nChange in \\nShort-Term \\nDebt\\nChange in \\nLong-Term \\nDebt\\nNet Cash from \\nFinancing\\nCash at Beginning \\nof Period$458,575 $400,150 $288,063 $155,025 ($550) ($165,088) ($342,851) ($477,521) ($599,180) ($711,674) ($793,677) ($857,277)\\nNet Change in \\nCash($58,425) ($112,088) ($133,038) ($155,575) ($164,538) ($177,764) ($134,669) ($121,659) ($112,494) ($82,003) ($63,600) ($44,724)\\nCash at End of \\nPeriod$400,150 $288,063 $155,025 ($550) ($165,088) ($342,851) ($477,521) ($599,180) ($711,674) ($793,677) ($857,277) ($902,001)' metadata={'source': 'first_rule3.pdf', 'page': 56}\n",
      "page_content='First Rule\\n57\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.2023 2024 2025 2026 2027\\nNet Cash Flow from Operations\\nNet Profit ($44,000) ($1,364,912) $1,776,515 $18,214,498 $80,933,190\\nDepreciation & Amortization\\nChange in Accounts Receivable $0 ($28,639) ($55,064) ($351,079) ($1,168,338)\\nChange in Inventory\\nChange in Accounts Payable $2,575 $32,975 $10,374 $28,223 $34,666\\nChange in Income Tax Payable $0 $0 $139,436 $1,782,852 $6,231,167\\nChange in Sales Tax Payable $0 $0 $0 $0\\nChange in Prepaid Revenue $0 $0 $0 $0 $0\\nNet Cash Flow from Operations ($41,425) ($1,360,576) $1,871,260 $19,674,494 $86,030,686\\nInvesting & Financing\\nAssets Purchased or Sold\\nNet Cash from Investing\\nInvestments Received $500,000\\nDividends & Distributions\\nChange in Short-Term Debt\\nChange in Long-Term Debt\\nNet Cash from Financing $500,000\\nCash at Beginning of Period $0 $458,575 ($902,001) $969,259 $20,643,753\\nNet Change in Cash $458,575 ($1,360,576) $1,871,260 $19,674,494 $86,030,686\\nCash at End of Period $458,575 ($902,001) $969,259 $20,643,753 $106,674,438' metadata={'source': 'first_rule3.pdf', 'page': 57}\n"
     ]
    }
   ],
   "source": [
    "for page in pages:\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key = openai.api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Pinecone.from_documents(docs, embeddings, index_name=\"bplan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key = pinecone_key, environment=pinecone_env) # Initialize pinecone\n",
    "index = pinecone.Index(\"bplan\") # Get the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "\n",
    "repo = Repo.clone_from(\n",
    "    \"https://github.com/tiangolo/fastapi\", to_path=\"./example_data/test_repo1\"\n",
    ")\n",
    "branch = repo.head.reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"openai.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PythonLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "# Initialize the document loader.  Use the glob\n",
    "loader = DirectoryLoader('../../bakespace_fastapi/', loader_cls=PythonLoader, glob='**/*.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "BakeSpace Partner API Version 1.40  \n",
      " \n",
      "This document will outline the query structure for the BakeSpace partner API. The purpose is \n",
      "so that partners can retrieve bakespace recipe information for their display purposes.  \n",
      " \n",
      "The basic structure of a query is:  \n",
      " \n",
      "http://bakespace.com/api/query.php?pcode=<partner_code>&type=<type>&limit=<number>  \n",
      " \n",
      "where partner_code  is an alphanumeric string the partner is assigned by BakeSpace, type is \n",
      "the query type, and limit is how many results are to be returned.  \n",
      " \n",
      "Reply content type is XML and a typical replay structure is as follows:  \n",
      " \n",
      "<results>  \n",
      "   <count></count>  \n",
      "   <item> \n",
      "      <recipeid></recipeid>  \n",
      "      <name></name>  \n",
      "      <author></author>  \n",
      "      <chosendate></chosendate>  \n",
      "      <foodimg></foodimg>  \n",
      "      <thumbnailimg></thumbn ailimg> \n",
      "      <fullimg></fullimg>  \n",
      "      <desc></desc>  \n",
      "      <preptime></preptime>  \n",
      "      <cooktime></cooktime>  \n",
      "      <servings></servings>  \n",
      "      <directions></directions>  \n",
      "      <ingredients></ingredients>  \n",
      "   </item> \n",
      "   <item> \n",
      "        ... another recipe ...  \n",
      "   </item> \n",
      "</results>  \n",
      " \n",
      "Note that only the recipeoftheday  type will include the \"chosendate\" field in the reply.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Query parameter details for “type” are as follows:  \n",
      " \n",
      "type:  recipeOfTheDay  \n",
      " \n",
      "Description:  \n",
      "Returns the designated recipe(s) of the day in orde r by day chosen descending.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 1  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<count>1</count>\n",
      "<item> \n",
      "<recipeid>8493</recipeid>  \n",
      "<name>Chocolate Lover's Creme Brulee</name>  \n",
      "<author>Laurie Reinmann</author>  \n",
      "<chosendate>20 11-07-27</chosendate>  \n",
      "<foodimg>4ee1b0c3a736bcb97ab13bf09a68f53e.jpeg</foodimg>\n",
      "<thumbnailimg>  \n",
      "http://bakespace.dougco.com/images/small/4ee1b0c3a736bcb97ab13bf09a68f53e.jpeg  \n",
      "</thumbnailimg>\n",
      "<fullimg>  \n",
      "http://bakespace.dougco.com/images/large/4ee1b0c3a736bcb9 7ab13bf09a68f53e.jpeg  \n",
      "</fullimg>\n",
      "<desc/> \n",
      "<preptime/>  \n",
      "<cooktime/>  \n",
      "<servings>4</servings>\n",
      "<directions > \n",
      "Position a rack in the center of the oven and preheat to 325 degrees F. Have a pot of \n",
      "boiling water ready. In a saucepan over medium heat, warm the cream u ntil small \n",
      "bubbles form around the edges of the pan, 2 to 3 minutes. Remove from the heat and \n",
      "stir in the chocolate until melted and blended. Cool slightly. In a bowl, whisk \n",
      "together the egg yolks and 2 tablespoons of the sugar until the mixture is pale ye llow \n",
      "and thick ribbons fall from the whisk, about 5 minutes. Slowly stir in the warm \n",
      "chocolate/cream mixture, then stir in the vanilla. Line a 3 -inch deep baking pan with \n",
      "a kitchen towel and place four 6 -ounce ramekins or dessert cups in the pan. Pour the \n",
      "chocolate mixture through a fine -mesh sieve set over a bowl. Divide the chocolate \n",
      "mixture among the ramekins. Add the boiling water to fill the pan halfway up the sides \n",
      "of the ramekins and cover loosely with aluminum foil. Bake until the custards are just \n",
      "set around the edges, 25 to 30 minutes. Transfer the ramekins to a wire rack and cool \n",
      "to room temperature. Cover and refrigerate for at least 4 hours or up to 2 days. Just \n",
      "before serving, sprinkle 1 tablespoon sugar evenly over the surface of each custard.  \n",
      "Using a kitchen torch, move the flame continuously in small circles over the surface \n",
      "until the sugar bubbles and just begins to turn golden, 20 to 30 seconds per custard. \n",
      "Garnish with a few raspberries, a dollop of whipped cream and a sprig of mint, if \n",
      "desired. Serve immediately.  \n",
      "</directions>\n",
      "<ingredients>  \n",
      "2 cups heavy cream 3 ounces good quality bittersweet chocolate, chopped into small \n",
      "pieces 3 large egg yolks 6 tablespoons granulated sugar, divided 1 teaspoon vanilla \n",
      "extract \n",
      "</ingredients>\n",
      "</item>\n",
      "</results> \n",
      " \n",
      " \n",
      "type:  featuredRecipes  \n",
      " \n",
      "Description:  \n",
      "Returns recipes that have been marked as featured recipes in a unique order that \n",
      "changes daily.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 1  \n",
      " \n",
      "Reply:  \n",
      "Same as recipedOfTheDay  \n",
      " \n",
      " \n",
      " \n",
      "type:  lat estRecipes  \n",
      " \n",
      "Description:  \n",
      "Returns recipes in order by timestamp created descending. Only includes recipes that \n",
      "have a photo.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return structur e, defaults to row zero \n",
      "which is the first one.  \n",
      " \n",
      "Reply:  \n",
      "Same as recipedOfTheDay  \n",
      " \n",
      " \n",
      "type:  myRecipeBox  \n",
      " \n",
      "Description:  \n",
      "Returns recipes in the currently authenticated user's recipe box.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow: optional; which row to start on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      " \n",
      "Reply:  \n",
      "Same as recipedOfTheDay  \n",
      " \n",
      " \n",
      "type:  myRecipeBoxTagged  \n",
      " \n",
      "Description:  \n",
      "Returns recipes in the currently authenticated user's recipe box that are tagg ed with the \n",
      "supplied parameter.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      "tag: required; what tag to filter on, default s to “litl”  \n",
      " \n",
      "Reply:  \n",
      "Same as recipedOfTheDay  \n",
      " \n",
      " \n",
      "type:  addRecipe  \n",
      " \n",
      "Description:  \n",
      "Will add a recipe to the authenticated user's recipe box and tag it with the suppied tag. \n",
      "Requires key of “recipeid”.  \n",
      " \n",
      "Parameters:  \n",
      "recipeid : required; a valid recipe id  \n",
      "tag: requi red; what tag to filter on, defaults to “litl”  \n",
      " \n",
      "Error Replies:  \n",
      "Invalid recipe ID  \n",
      "Recipe already exists in recipe box  \n",
      "Not authenticated  \n",
      "Save failed  \n",
      " \n",
      "format example:  \n",
      "<results>  \n",
      "<error>Invalid recipe ID</error>  \n",
      "</results>  \n",
      " \n",
      "Result Reply:  \n",
      "Success  \n",
      " \n",
      "format example : \n",
      "<results>  \n",
      "<result>Success</result>  \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  version  \n",
      " \n",
      "Description:  \n",
      "Returns the API version in use currently.  \n",
      " \n",
      "Parameters:  \n",
      "None \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<version>  \n",
      "<revision>1.3</revision>  \n",
      "<timestamp>2011 -07-28</timestamp>  \n",
      "</version>  \n",
      "</results>  \n",
      " \n",
      " \n",
      "type:   brandDetails  \n",
      " \n",
      "Description:  \n",
      "Returns list of Brand logos and URL links.  \n",
      " \n",
      "Parameters:  \n",
      "None \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<brand> \n",
      "<name>Bobs Pancake House</name>  \n",
      "<url>http://www.pancakes.com</url>  \n",
      "<fullimg>http://www.pancakes.com/images/logo.jpg</fullimg>  \n",
      "</brand>  \n",
      "<brand> \n",
      "<name>Joes Sausage House</name>  \n",
      "<url>http://www.sausages.com</url>  \n",
      "<fullimg>http://www.sausages.com/images/logo.jpg</fullimg>  \n",
      "</brand>  \n",
      "</results>  \n",
      " \n",
      " \n",
      "type:  getLatestReviews  \n",
      " \n",
      "Description:  \n",
      "Returns list of latest cookbook reviews.  \n",
      " \n",
      "Parameters:  \n",
      "limit: option al; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      "cookbookid : optional; limit reviews to a specific cookbookid  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1 </cookbook_id>  \n",
      "  <cookbook_title>Summer Cooking</cookbook_title>  \n",
      "  <author>Bob Jones</author>  \n",
      "  <review_text>I liked it. I really liked it!</review_text>  \n",
      "  <is_owned>true</is_owned>  \n",
      "  <downloads>3</downloads>  \n",
      " </item> \n",
      " <item> \n",
      "   ... \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  getFeaturedAuthor  \n",
      " \n",
      "Description:  \n",
      "Returns list of the current featured author.  \n",
      " \n",
      "Parameters:  \n",
      "None \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <author>Bob Jones</author>  \n",
      "  <author_member_id>12</author_member_id>  \n",
      "  <author_facebook>http://facebook.com/myusername</author _facebook>  \n",
      "  <author_twitter>http://twitter.com/myusername</author_twitter>  \n",
      "  <about>Bob is from a small town and likes cats. He likes all kind of \n",
      "cats.</about>  \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  getCookbookProfile  \n",
      " \n",
      "Description:  \n",
      "Returns details of a specified c ookbook.  \n",
      " \n",
      "Parameters:  \n",
      "cookbookid : required  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1</cookbook_id>  \n",
      "  <title>Bob's Cookbook</title>  \n",
      "  <description>Bob made this cookbook one rainy sunday \n",
      "afternoon.</description>  \n",
      "  <cost>7.95</cost>  \n",
      "  <overall_rating />  \n",
      "  <author_name>Bob Jones</author_name>  \n",
      "  <author_member_id>45783</author_member_id>  \n",
      "  \n",
      "<author_member_img>http://bakespace.com/images/normal/xxxx.jpg</author_member_\n",
      "img> \n",
      "  <recipe_count>13</recipe_count>  \n",
      "  <location_created>Los Angeles, CA, USA</location_creat ed> \n",
      "  <language>English</language>  \n",
      "  <categories>Dessert, Beverage</categories>  \n",
      "  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \n",
      "  <videourl>http://www.youtube.com/?v=939djdj</videourl>  \n",
      "  <video_thumbnail> http://bakespace.com/images/video.jpg </video_thumbnail>  \n",
      "  <facebook />  \n",
      "  <twitter />  \n",
      "  <is_owned>true</is_owned>  \n",
      "  <downloads>3</downloads>  \n",
      "  <reviews>  \n",
      "   <review>  \n",
      "    <title>Jane's review</title>  \n",
      "    <synopsis>Loved it!</sy nopsis> \n",
      "    <rating>4</rating>  \n",
      "   </review>  \n",
      "  </reviews>  \n",
      "  <recipes>  \n",
      "     <recipe>  \n",
      "      <recipe_id>49030</recipe_id>  \n",
      "      <sample>YES</sample>  \n",
      "      <name>Mexican Hot Chocolate Brownies</name>  \n",
      "      <summary>Sweet meets heat</summary>  \n",
      "      <duration>25< /duration>  \n",
      "      <servings>20 -24</servings>  \n",
      "      <ingredients>1 1/4 cup cake flour, 1/2 tsp salt</ingredients>  \n",
      "      <directions>  \n",
      "       <item>Preheat oven to 325. Grease the bottom and sides of a 13×9 \n",
      "pan.</item>  \n",
      "       <item>Whisk cake flour, salt, baki ng powder, cayenne, and cinnamon in a  \n",
      "medium bowl. Set aside.</item>  \n",
      "       <item>Place chocolate and butter in a bowl. Microwave for 1 minute and \n",
      "in 30 second increments, stirring in between until chocolate has completely \n",
      "melted. Pour into the bowl of you r stand mixer. Add sugar and mix on med -high \n",
      "until combined. Turn mixer to low and add 1 egg at a time and mix completely. \n",
      "Add vanilla.</item>  \n",
      "       <item>Pour batter into prepared pan and bake for ~30 minutes, until a \n",
      "skewer inserted in the center comes out with a few moist crumbs attached. Let \n",
      "cool ~15 minutes.</item>  \n",
      "       <item>Heat semisweet chocolate and milk in the microwave for 30 seconds  \n",
      "and then in 15 second increments, stirring in between until chocolate has \n",
      "completely melted. Pour over brownie s. Let cool completely before \n",
      "cutting.</item>  \n",
      "      </directions>  \n",
      "      <backstory>Sweet meets heat</backstory>  \n",
      "      \n",
      "<imgurl>http://bakespace.com/images/large/1e2a67029869c515b38d872e661cf78e.jpe\n",
      "g</imgurl>  \n",
      "      <videourl></videourl>  \n",
      "      <notes></notes>  \n",
      "     </recipe>  \n",
      "     <recipe>  \n",
      "      <recipe_id>49030</recipe_id>  \n",
      "      <sample>YES</sample>  \n",
      "      <name>Mexican Hot Chocolate Brownies</name>  \n",
      "      <summary>Sweet meets heat</summary>  \n",
      "      <duration>25</duration>  \n",
      "      <servings>20 -24</servings>  \n",
      "      <ingredients>1 1/4 cup cake flour, 1/2 tsp salt</ingredients>  \n",
      "      <directions>  \n",
      "       <item>Preheat oven to 325. Grease the bottom and sides of a 13×9 \n",
      "pan.</item>  \n",
      "       <item>Whisk cake flour, salt, baking powder, cayenne, and cinnamon in a  \n",
      "medium bowl. Se t aside.</item>  \n",
      "       <item>Place chocolate and butter in a bowl. Microwave for 1 minute and \n",
      "in 30 second increments, stirring in between until chocolate has completely \n",
      "melted. Pour into the bowl of your stand mixer. Add sugar and mix on med -high \n",
      "until co mbined. Turn mixer to low and add 1 egg at a time and mix completely. \n",
      "Add vanilla.</item>  \n",
      "       <item>Pour batter into prepared pan and bake for ~30 minutes, until a \n",
      "skewer inserted in the center comes out with a few moist crumbs attached. Let \n",
      "cool ~15 mi nutes.</item>  \n",
      "       <item>Heat semisweet chocolate and milk in the microwave for 30 seconds  \n",
      "and then in 15 second increments, stirring in between until chocolate has \n",
      "completely melted. Pour over brownies. Let cool completely before \n",
      "cutting.</item>  \n",
      "      </directions>  \n",
      "      <backstory>Sweet meets heat</backstory>  \n",
      "      \n",
      "<imgurl>http://bakespace.com/images/large/1e2a67029869c515b38d872e661cf78e.jpe\n",
      "g</imgurl>  \n",
      "      <videourl></videourl>  \n",
      "      <notes></notes>  \n",
      "     </recipe>  \n",
      "  </recipes>  \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  getCookbooks  \n",
      " \n",
      "Description:  \n",
      "Returns list of user's downloaded Cookbooks, i.e., ones that they bought/downloaded \n",
      "but did not necessarily create.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to star t on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1</cookbook_id>  \n",
      "  <title>Sandwitches</title>  \n",
      "  <description>Come explore my cookbook</description>  \n",
      "  <cover_imgurl>http://www.imagesgalore.com/ images/mycover.jpg</cover_imgurl>  \n",
      "  <recipe_count>13</recipe_count>  \n",
      "  <cost>1.99</cost>  \n",
      "  <facebook />  \n",
      "  <twitter />  \n",
      "  <is_owned />  \n",
      "  <downloads>5</downloads>  \n",
      " </item> \n",
      " <item> \n",
      "  ... \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      " \n",
      "type:  downloadCookbook  \n",
      " \n",
      "Description:  \n",
      "Returns detail s of a Cookbook to download.  \n",
      " \n",
      "Parameters:  \n",
      "cookbookid: required  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1</cookbook_id>  \n",
      "  <title>Bob's Cookbook</title>  \n",
      "  <description>Bob made this cookbook one rainy sunday \n",
      "afternoon.</description>  \n",
      "  <cost>7.95</cost>  \n",
      "  <author_member_id>45783</author_member_id>  \n",
      "  <author_name />  \n",
      "  <author_member_img />  \n",
      "  <recipe_count>13</recipe_count>  \n",
      "  <location_created>Los Angeles, CA, USA</location_created>  \n",
      "  <language>English</language>  \n",
      "  <categories>Dessert, Beverage</categories>  \n",
      "  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \n",
      "  <videourl>http://www.youtube.com/?v=939djdj</videourl>  \n",
      "  <video_thumbnail />  \n",
      "  <facebook />  \n",
      "  <twitter />  \n",
      "  <recipes>  \n",
      "   <recipe>  \n",
      "    <recipe_id>1</recipe_id>  \n",
      "    <name>Spinach Di p</name>  \n",
      "    <summary>Tasty beyond belief, spinach is good for you also!</summary>  \n",
      "    <duration>13</duration>  \n",
      "    <servings>26</servings>  \n",
      "    <ingredients>2 cups Basil, 2 Tomatoes, 2 cups Spinach</ingredients>  \n",
      "    <equipment>1 Firehose</equipment>  \n",
      "    <directions>Cook it all up; serve hot</directions>  \n",
      "    <backstory>I made this once when I was a fireman back in \n",
      "Colorado.</backstory>  \n",
      "    <imgurl> </imgurl>  \n",
      "    <videourl> </videourl>  \n",
      "    <notes> </notes>  \n",
      "   </recipe>  \n",
      "   <recipe>  \n",
      "     ... \n",
      "   </recipe>  \n",
      "  </recipes> \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      " \n",
      "type:  getCookbookLatest  \n",
      " \n",
      "Description:  \n",
      "Returns list of latest Cookbooks.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      "costlimit : optional; indicates max cost in US dollars for return list items  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<item> \n",
      "<cookbook_id>1</cookbook_id>  \n",
      "<title>Bob's Cookbook</title>  \n",
      "<description>Bob made this cookbook one rainy sunday afternoon.</descrip tion> \n",
      "<cost>7.95</cost>  \n",
      "<author_member_id>45783</author_member_id>  \n",
      "<author_name/>  \n",
      "<author_member_img/>  \n",
      "<recipe_count>13</recipe_count>  \n",
      "<location_created/>  \n",
      "<language/>  \n",
      "<categories/>  \n",
      "<cover_imgurl/>  \n",
      "<video_thumbnail>http://www.imagesgalore.com/images/love.jp g</video_thumbnail>  \n",
      "<videourl>http://www.youtube.com/?v=939djdj</videourl>  \n",
      "<facebook/>  \n",
      "<twitter/>  \n",
      "<is_owned/>  \n",
      "<downloads/>  \n",
      "<reviews>  \n",
      " <review>  \n",
      "  <cookbook_id>13</cookbook_id>  \n",
      "  <cookbook_title>Bob's Cookbook</cookbook_title>  \n",
      "  <author>Jane Doe</author>  \n",
      "  <review_text>Loved it!</review_text>  \n",
      "  <is_owned/>  \n",
      "  <downloads/>  \n",
      " </review>  \n",
      "</reviews>  \n",
      "</item> \n",
      "<item> \n",
      "  ... \n",
      "</item> \n",
      "</results>  \n",
      " \n",
      " \n",
      "type:  topFreeCookbooks  \n",
      " \n",
      "Description:  \n",
      "Returns list of top free Cookbooks.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return , defaults to 10  \n",
      "startrow : optional; which row to start on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<item> \n",
      "<cookbook_id>1</cookbook_id>  \n",
      "<title>Bob's Cookbook</title>  \n",
      "<description>Bob made this cookbook one rainy sunday afternoon.</description>  \n",
      "<cost>0</cost>  \n",
      "<overall_rating/>  \n",
      "<author_name/>  \n",
      "<author_member_id>45783</author_member_id>  \n",
      "<author_member_img/>  \n",
      "<recipe_count>13</recipe_count>  \n",
      "<location_created/>  \n",
      "<language/>  \n",
      "<categories/>  \n",
      "<cover_imgurl/>  \n",
      "<video_thumbnail>h ttp://www.imagesgalore.com/images/love.jpg</video_thumbnail>  \n",
      "<videourl>http://www.youtube.com/?v=939djdj</videourl>  \n",
      "<facebook/>  \n",
      "<twitter/>  \n",
      "<is_owned/>  \n",
      "<downloads/>  \n",
      "<reviews>  \n",
      " <review>  \n",
      "  <cookbook_id>13</cookbook_id>  \n",
      "  <cookbook_title>Bob's Cookbook</cookbo ok_title>  \n",
      "  <author>Jane Doe</author>  \n",
      "  <review_text>Loved it!</review_text>  \n",
      "  <is_owned/>  \n",
      "  <downloads/>  \n",
      " </review>  \n",
      "</reviews>  \n",
      "</item> \n",
      "<item> \n",
      "  ... \n",
      "</item> \n",
      "</results>  \n",
      " \n",
      " \n",
      "type:  getCookbookFeatured  \n",
      " \n",
      "Description:  \n",
      "Returns list of featured Cookbooks.  \n",
      " \n",
      "Paramete rs: \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      "costlimit : optional; indicates max cost in US dollars for return list items  \n",
      " \n",
      "Reply:  \n",
      "Same as getCookbookLatest  \n",
      " \n",
      " \n",
      " \n",
      "type:  getCookbookNews  \n",
      " \n",
      "Description:  \n",
      "Returns list of Cookbook news, and deal of the day  \n",
      " \n",
      "Parameters:  \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return structure, default s to row zero \n",
      "which is the first one.  \n",
      "costlimit : optional; indicates max cost in US dollars for return list items  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<item> \n",
      "<cookbook_id>1</cookbook_id>  \n",
      "<title>Bob's Cookbook</title>  \n",
      "<description>Bob made this cookbook one rainy sunday after noon.</description>  \n",
      "<imgurl/>  \n",
      "<cost>7.95</cost>  \n",
      "<author_member_id>45783</author_member_id>  \n",
      "<recipe_count>13</recipe_count>  \n",
      "<facebook/>  \n",
      "<twitter/>  \n",
      "<is_owned/>  \n",
      "<downloads/>  \n",
      "<top_downloads>  \n",
      " <download>  \n",
      "  <title>Jane's review</title>  \n",
      "  <imgurl>http://www.image sgalore.com/images/love.jpg</imgurl>  \n",
      "  <cost>3.95</cost>  \n",
      " </download>  \n",
      " <download>  \n",
      "   ... \n",
      " </download>  \n",
      "</top_downloads>  \n",
      "</item> \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  myCookbooks  \n",
      " \n",
      "Description:  \n",
      "Returns list of users's Cookbooks that the user created.  \n",
      " \n",
      "Parameters:  \n",
      "limit: optio nal; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return structure, defaults to row zero \n",
      "which is the first one.  \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<item> \n",
      "<cookbook_id>1</cookbook_id>  \n",
      "<title/>  \n",
      "<description/>  \n",
      "<cover_imgurl>http://www .imagesgalore.com/images/mycover.jpg</cover_imgurl>  \n",
      "<cost>1.99</cost>  \n",
      "<recipe_count>13</recipe_count>  \n",
      "<facebook/>  \n",
      "<twitter/>  \n",
      "<downloads>3</downloads>  \n",
      "</item> \n",
      "</results>  \n",
      " \n",
      " \n",
      "type:  getTopCookbookCategories  \n",
      " \n",
      "Description:  \n",
      "Returns list of top cookbook categories . \n",
      " \n",
      "Parameters:  \n",
      "None \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<item> \n",
      " <category_id>1</category_id>  \n",
      " <name>Bread</name>  \n",
      "</item> \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  getSubCookbookCategories  \n",
      " \n",
      "Description:  \n",
      "Returns list of sub cookbook categories.  \n",
      " \n",
      "Parameters:  \n",
      "None \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<item> \n",
      " <categor y_id>8</category_id>  \n",
      " <name>Crackers</name>  \n",
      " <parent>Bread</parent>  \n",
      "</item> \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "type:  searchCookbooks  \n",
      " \n",
      "Description:  \n",
      "Returns list of cookbooks based on search parameters.  \n",
      " \n",
      "Parameters:  \n",
      "keywords : text; optional, set to search on keywords, comma se parated list  \n",
      "keywordmatch : text; optional, set to \"any\" to match any keyword in \"keywords\" \n",
      "otherwise it requires match all  \n",
      "searchcategories : text; optional, set to category Ids, comma separated list  \n",
      "ingredmatch : text; optional, set to match ingredient keyw ords, comma separated list  \n",
      "searchauthor : text; optional, set to member ID of author  \n",
      "searchsift : text; optional, set to option for sifting (i.e.: all, non -profit, pro, brands, \n",
      "blogger). Default is “all”  \n",
      "searchtype : optional; \"bookstore\" for cookbook store, \"all\" for all recipes, \"my\" for \n",
      "user's recipes, \"authorcookbooks\" will return other cookbooks by author in cookbookid, \n",
      "\"alsobought\" will return other cookbooks bought by people who bought cookbookid  \n",
      " \n",
      "Error Reply:  \n",
      "All search keywords must be at least 2 char acters in length  \n",
      " \n",
      "Results Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1</cookbook_id>  \n",
      "  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \n",
      "  <title>Sunday cooking</title>  \n",
      "  <description/>  \n",
      "  <cost>7.95</cost>  \n",
      "  <author_name/>  \n",
      "  <author_ member_id/>  \n",
      "  <videourl/>  \n",
      "  <video_thumbnail/>  \n",
      "  <recipe_count>13</recipe_count>  \n",
      "  <facebook/>  \n",
      "  <twitter/>  \n",
      "  <is_owned/>  \n",
      "  <downloads>5</downloads>  \n",
      " </item> \n",
      " <item> \n",
      "  ... \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      "If the search type is “my”, then the XML will output recipe inf ormation instead of \n",
      "cookbook information, as follows:  \n",
      " \n",
      "<item> \n",
      " <recipe_id>49954</recipe_id>  \n",
      " <name>Angel Acres Baked Pineapple Pudding</name>  \n",
      " <author>angelacres</author>  \n",
      " <foodimg>4467a79f19383b25c9675153bb68253b.jpeg</foodimg>  \n",
      " \n",
      "<thumbnailimg>http://bake space.com/images/small/4467a79f19383b25c9675153bb6825\n",
      "3b.jpeg</thumbnailimg>  \n",
      " \n",
      "<imgurl>http://bakespace.com/images/small/4467a79f19383b25c9675153bb68253b.jpe\n",
      "g</imgurl>  \n",
      " \n",
      "<fullimg>http://bakespace.com/images/large/4467a79f19383b25c9675153bb68253b.jp\n",
      "eg</fullimg > \n",
      " <desc>This recipe comes from my mother -in-law Carol Deibel and she is a \n",
      "fabulous cook! We think everyone should be able to follow her simple, yet \n",
      "delicious pineapple pudding recipe and make it perfect every time!</desc>  \n",
      " <preptime>5</preptime>  \n",
      " <cooktim e>50-60</cooktime>  \n",
      " <servings>10</servings>  \n",
      " <directions>Heat oven to 350 degrees Combine ingredients in large bowl, \n",
      "mixing till just blended together. Place in greased casserole dish. Bake for \n",
      "50-60 minutes</directions>  \n",
      " <ingredients>2 T. flour 1 can crus hed pineapple ¼ lb butter, melted ½ cup \n",
      "sugar 3 eggs, beaten 4 slices white bread, crust removed, cubed</ingredients>  \n",
      "</item> \n",
      "   \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      "type:  topCookbooks  \n",
      " \n",
      "Description:  \n",
      "Returns list of top cookbooks.  \n",
      " \n",
      "Parameters:  \n",
      "timeperiod : Optional, used for cookbook sear ches; “thisweek”, “lastweek”, “thismonth”, \n",
      "“lastmonth”; default is all  \n",
      "costlimit : optional; indicates max cost in US dollars for return list items  \n",
      "limit: optional; how many rows to return, defaults to 10  \n",
      "startrow : optional; which row to start on the return  structure, defaults to row zero \n",
      "which is the first one.  \n",
      " \n",
      "Results Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1</cookbook_id>  \n",
      "  <last_updated>2011 -09-10</last_updated>  \n",
      "  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \n",
      "  <title>Sunda y cooking</title>  \n",
      "  <description>Bob made this cookbook one rainy sunday \n",
      "afternoon.</description>  \n",
      "  <cost>7.95</cost>  \n",
      "  <author_name/>  \n",
      "  <author_member_id/>  \n",
      "  <author_member_img/>  \n",
      "  <recipe_count>13</recipe_count>  \n",
      "  <videourl/>  \n",
      "  <video_thumbnail/>  \n",
      "  <facebook/> \n",
      "  <twitter/>  \n",
      "  <is_owned/>  \n",
      "  <downloads>4</downloads>  \n",
      " </item> \n",
      " <item> \n",
      "  ... \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  getRecipe  \n",
      " \n",
      "Description:  \n",
      "Returns details of a specified recipe.  \n",
      " \n",
      "Parameters:  \n",
      "recipeid : the id of the requested recipe.  \n",
      " \n",
      "Reply:  \n",
      "Same as recipedO fTheDay  \n",
      " \n",
      " \n",
      "type:  getRecipes  \n",
      " \n",
      "Description:  \n",
      "Returns details for a list of recipes.  \n",
      " \n",
      "Parameters:  \n",
      "recipeids : the ids of the requested recipes separated by commas  \n",
      " \n",
      "Reply:  \n",
      "Same as recipedOfTheDay  \n",
      " \n",
      " \n",
      "type:  addNote  \n",
      " \n",
      "Description:  \n",
      "Allows user to add a private note a pplied to a specified recipe.  \n",
      " \n",
      "Parameters:  \n",
      "recipeid : the id of the recipe, required  \n",
      "notetext :  the text of the note, required  \n",
      " \n",
      "Error Replies:  \n",
      "Invalid recipe ID  \n",
      "Not authenticated  \n",
      "Note text invalid  \n",
      "Save failed  \n",
      " \n",
      "format example:  \n",
      "<results>  \n",
      "<error>Invalid recipe  ID</error>  \n",
      "</results>  \n",
      " \n",
      "Result Reply:  \n",
      "Success  \n",
      " \n",
      " \n",
      " \n",
      "type:  login  \n",
      " \n",
      "Description:  \n",
      "Allows a user to authenticate which sets the appropriate cookies. Will set login cookies \n",
      "and return a 32 character session ID that can be used in cases where cookies are not \n",
      "suppor ted. \n",
      " \n",
      "Parameters:  \n",
      "authu : the username, required  \n",
      "authp :  the password, required  \n",
      " \n",
      "Error Replies:  \n",
      "Invalid username  \n",
      "Invalid password  \n",
      "User banned  \n",
      "Login failed  \n",
      " \n",
      "format example:  \n",
      "<results>  \n",
      "<error>Invalid username</error>  \n",
      "</results>  \n",
      " \n",
      "Result Reply:  \n",
      "<results>  \n",
      "<sid>dxBKecejS1b41VVmqHp97fOnwYKXS2zf</sid>  \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      "type:  logout  \n",
      " \n",
      "Description:  \n",
      "Allows a user to sign out which clears the appropriate cookies.  \n",
      " \n",
      "Parameters:  \n",
      "None \n",
      " \n",
      "Replies:  \n",
      "<results>  \n",
      "<result>Success</result>  \n",
      "</results>  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "List of key/value pairs that are u sed outside of “type”:  \n",
      " \n",
      "Key Name  Key Value  Description  \n",
      "pcode  Alphanumeric code  A unique code assigned to a partner by \n",
      "BakeSpace  \n",
      "sessionid  Alphanumeric code  A session id that was retrieved via the login \n",
      "call. Passed along with user -authenticated \n",
      "requests.  \n",
      "[ Note that cookies will also work in lieu of \n",
      "explicitly passing the SID ]  \n",
      "limit Number  An integer that defines how many results to \n",
      "return. Maximum is 100.  \n",
      "startrow  Number  An integer that defines what row in the results \n",
      "to start returning items. Used fo r pagination.  \n",
      "timeperiod  Text Optional, used for cookbook searches; \n",
      "“thisweek”, “lastweek”, “thismonth”, \n",
      "“lastmonth”  \n",
      "costlimit  Decimal Number  Optional; indicates max cost for return list  \n",
      "authu  Text A username for authentication (used with \n",
      "\"type\" set to  login)  \n",
      "authp  Text A password for authentication (used with \"type\" \n",
      "set to login)  \n",
      "keywords  Text Comma separated list of word used with type \n",
      "“search”  \n",
      "keywordmatch  Text Used with type “search”, is set to “any” then \n",
      "“keywords” will match if any match, other wise \n",
      "they must all match to return in the search.  \n",
      "ingredmatch  Text Optional; set to match ingredient keywords, \n",
      "comma separated list  \n",
      "membermatch  Text Optional, set to match member username text  \n",
      "searchcategories  Text Optional, set as list of category Ids,  comma \n",
      "separated list  \n",
      "searchauthor  Text Optional, set with a member ID to limit search \n",
      "to that author  \n",
      "searchsift  Text Optional, set to sift type (all, non -profit, pro, \n",
      "brands, blogger). Default is “all”  \n",
      "searchtype  Text Optional; \"bookstore\" for cookbook  store, \"all\" \n",
      "for all recipes, \"my\" for user's recipes, \n",
      "\"authorcookbooks\" will return other cookbooks \n",
      "by author in cookbookid, \"alsobought\" will \n",
      "return other cookbooks bought by people who \n",
      "bought cookbookid  \n",
      "tag Text Used to provide a tag when adding a rec ipe. \n",
      "notetext  Text Text to use when using type “addNote”  \n",
      "recipebox  Text Options: “my” for user's own recipebox. Blank \n",
      "for all users.  \n",
      "recipeid  Integer  Required with type “addrecipe”  \n",
      "recipeids  Text Comma separated list of recipe ids  \n",
      "cookbookid  Integer  Required with type “addNote”  \n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key = pinecone_key, environment=pinecone_env) # Initialize pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key = openai.api_key,\n",
    "    disallowed_special=()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sjufa\\OneDrive\\Desktop\\Current Projects\\vl_demo\\tests\\langchain.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a chroma db from the documents\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Chroma\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m vectorstore \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39mfrom_documents(docs, embed)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embed' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a chroma db from the documents\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each doc in docs, create a list of tuples, where each tuple is doc.page_content, doc.metadata['source']\n",
    "docs_list = [(doc.page_content, doc.metadata['source']) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18601"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the token length of each doc\n",
    "docs_token_length = [tiktoken_len(doc[0]) for doc in docs_list]\n",
    "\n",
    "# Sum the token lengths\n",
    "sum(docs_token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:09:28 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '3ca05cda57b9b205c0e2bce41fdc7ce0', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e67aeda6af7f4-BNA', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:09:37 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'd9a0b423ba8637c561e68acd2b69e53e', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e67e78aa1f7f4-BNA', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sjufa\\OneDrive\\Desktop\\Current Projects\\vl_demo\\tests\\langchain.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#Y134sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m index\u001b[39m.\u001b[39;49msimilarity_search(query, k\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\vectorstores\\chroma.py:261\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[1;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[0;32m    245\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    246\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    250\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m    251\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[0;32m    253\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(query, k, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[0;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\vectorstores\\chroma.py:345\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[1;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[0;32m    339\u001b[0m         query_texts\u001b[39m=\u001b[39m[query],\n\u001b[0;32m    340\u001b[0m         n_results\u001b[39m=\u001b[39mk,\n\u001b[0;32m    341\u001b[0m         where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m,\n\u001b[0;32m    342\u001b[0m         where_document\u001b[39m=\u001b[39mwhere_document,\n\u001b[0;32m    343\u001b[0m     )\n\u001b[0;32m    344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_query(query)\n\u001b[0;32m    346\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[0;32m    347\u001b[0m         query_embeddings\u001b[39m=\u001b[39m[query_embedding],\n\u001b[0;32m    348\u001b[0m         n_results\u001b[39m=\u001b[39mk,\n\u001b[0;32m    349\u001b[0m         where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m,\n\u001b[0;32m    350\u001b[0m         where_document\u001b[39m=\u001b[39mwhere_document,\n\u001b[0;32m    351\u001b[0m     )\n\u001b[0;32m    353\u001b[0m \u001b[39mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\embeddings\\openai.py:518\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m    510\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \n\u001b[0;32m    512\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_documents([text])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\embeddings\\openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \n\u001b[0;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\embeddings\\openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    375\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    376\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mtokens[i : i \u001b[39m+\u001b[39m _chunk_size],\n\u001b[0;32m    377\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invocation_params,\n\u001b[0;32m    378\u001b[0m     )\n\u001b[0;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\embeddings\\openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[1;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\chains\\llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='We expect profitability to correlate with platform adoption, backing our brand \\nmessaging of being the new industry standard, and development of native and \\ndownstream marketing opportunities. Conservatively, we forecast running at a loss \\nfor 18–24 months, but with an aim to generate revenue as early as December of \\n2023.', metadata={'page': 24.0, 'source': 'first_rule.pdf'}), Document(page_content='$16,783,471', metadata={'page': 30.0, 'source': 'first_rule.pdf'}), Document(page_content='Total Revenue $1,750 $9,000 $11,000 $17,350 $26,278 $44,222 $112,907 $144,351 $190,077 $299,727 $386,568 $723,746', metadata={'page': 40.0, 'source': 'first_rule.pdf'}), Document(page_content='$16,783,471', metadata={'page': 43.0, 'source': 'first_rule.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "print(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue $1,966,976 $16,783,471 $45,155,399 $122,734,165\n",
      "The relevant part of the context is:\n",
      "\n",
      "2023 2024 2025 2026 2027\n",
      "Total Revenue $1,966,976 $16,783,471 $45,155,399 $122,734,165\n",
      "\n",
      "This table contains the company's revenue targets for 2024 and other years.\n"
     ]
    }
   ],
   "source": [
    "for doc in compressed_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the company's revenue targets in 2024?\"\n",
    "\n",
    "# Similarity search\n",
    "results = index.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:12:37 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '228060595a56312e92070715d2777763', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e6c4dad9ef7d0-BNA', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sjufa\\OneDrive\\Desktop\\Current Projects\\vl_demo\\tests\\langchain.ipynb Cell 27\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#Y131sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m embeddings_filter \u001b[39m=\u001b[39m EmbeddingsFilter(embeddings\u001b[39m=\u001b[39membeddings, similarity_threshold\u001b[39m=\u001b[39m\u001b[39m0.76\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#Y131sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m compression_retriever \u001b[39m=\u001b[39m ContextualCompressionRetriever(base_compressor\u001b[39m=\u001b[39membeddings_filter, base_retriever\u001b[39m=\u001b[39mretriever)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sjufa/OneDrive/Desktop/Current%20Projects/vl_demo/tests/langchain.ipynb#Y131sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m compressed_docs \u001b[39m=\u001b[39m compression_retriever\u001b[39m.\u001b[39;49mget_relevant_documents(\u001b[39m\"\u001b[39;49m\u001b[39mWhat are the company\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms revenue targets in 2024?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\schema\\retriever.py:204\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m _kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expects_other_args \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 204\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    205\u001b[0m         query, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs\n\u001b[0;32m    206\u001b[0m     )\n\u001b[0;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\retrievers\\contextual_compression.py:46\u001b[0m, in \u001b[0;36mContextualCompressionRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_retriever\u001b[39m.\u001b[39mget_relevant_documents(\n\u001b[0;32m     43\u001b[0m     query, callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m docs:\n\u001b[1;32m---> 46\u001b[0m     compressed_docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_compressor\u001b[39m.\u001b[39;49mcompress_documents(\n\u001b[0;32m     47\u001b[0m         docs, query, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child()\n\u001b[0;32m     48\u001b[0m     )\n\u001b[0;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compressed_docs)\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\retrievers\\document_compressors\\embeddings_filter.py:57\u001b[0m, in \u001b[0;36mEmbeddingsFilter.compress_documents\u001b[1;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Filter documents based on similarity of their embeddings to the query.\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m stateful_documents \u001b[39m=\u001b[39m get_stateful_documents(documents)\n\u001b[1;32m---> 57\u001b[0m embedded_documents \u001b[39m=\u001b[39m _get_embeddings_from_stateful_docs(\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings, stateful_documents\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     60\u001b[0m embedded_query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39membed_query(query)\n\u001b[0;32m     61\u001b[0m similarity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_fn([embedded_query], embedded_documents)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\document_transformers\\embeddings_redundant_filter.py:66\u001b[0m, in \u001b[0;36m_get_embeddings_from_stateful_docs\u001b[1;34m(embeddings, documents)\u001b[0m\n\u001b[0;32m     64\u001b[0m     embedded_documents \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mstate[\u001b[39m\"\u001b[39m\u001b[39membedded_doc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m     65\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     embedded_documents \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49membed_documents(\n\u001b[0;32m     67\u001b[0m         [d\u001b[39m.\u001b[39;49mpage_content \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m documents]\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     69\u001b[0m     \u001b[39mfor\u001b[39;00m doc, embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(documents, embedded_documents):\n\u001b[0;32m     70\u001b[0m         doc\u001b[39m.\u001b[39mstate[\u001b[39m\"\u001b[39m\u001b[39membedded_doc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\embeddings\\openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \n\u001b[0;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\embeddings\\openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    375\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    376\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mtokens[i : i \u001b[39m+\u001b[39m _chunk_size],\n\u001b[0;32m    377\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invocation_params,\n\u001b[0;32m    378\u001b[0m     )\n\u001b[0;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\embeddings\\openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[1;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=embeddings_filter, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\"What are the company's revenue targets in 2024?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Rule\n",
      "24\n",
      "CONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \n",
      "information and is shared only with the understanding that you will not share its contents or ideas with \n",
      "third parties without the express written consent of the plan author.• Staffing: Engineers, support, executives, and marketers will make up a \n",
      "substantial part of operating expenses.\n",
      "• Acquisitions: The purchases of Controlla.XYZ, Emvoice, and Suno.AI should \n",
      "be viewed as key strategic investments.\n",
      "Profit Expectations\n",
      "We expect profitability to correlate with platform adoption, backing our brand \n",
      "messaging of being the new industry standard, and development of native and \n",
      "downstream marketing opportunities. Conservatively, we forecast running at a loss \n",
      "for 18–24 months, but with an aim to generate revenue as early as December of \n",
      "2023.\n",
      "In summary, First Rule's projections indicate an innovative, opportunity-rich \n",
      "venture poised for strategic growth. Aligning with industry trends and addressing \n",
      "unmet needs positions us uniquely. Continuous revenue streams and one-off \n",
      "opportunities create balance, supported by investment in ambassadorship and \n",
      "talent.\n",
      "While challenging, First Rule's originality and fit with the current art and tech \n",
      "landscape make it a promising investment. Projections match trends and endorse a \n",
      "model that resonates with stakeholders.\n",
      "First Rule\n",
      "40\n",
      "CONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \n",
      "understanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.2024 Jan '24 Feb '24 Mar '24 Apr '24 May '24 June '24 July '24 Aug '24 Sept '24 Oct '24 Nov '24 Dec '24\n",
      "Total Revenue $1,750 $9,000 $11,000 $17,350 $26,278 $44,222 $112,907 $144,351 $190,077 $299,727 $386,568 $723,746\n",
      "Total Direct \n",
      "Costs$8,750 $9,000 $9,500 $11,000 $12,000 $13,000 $14,500 $15,000 $15,500 $16,000 $16,500 $17,000\n",
      "Gross Margin ($7,000) $0 $1,500 $6,350 $14,278 $31,222 $98,407 $129,351 $174,577 $283,727 $370,068 $706,746\n",
      "Gross Margin % (400%) 0% 14% 37% 54% 71% 87% 90% 92% 95% 96% 98%\n",
      "Operating \n",
      "Expenses\n",
      "Salaries and \n",
      "Wages$34,000 $42,500 $55,000 $67,000 $68,000 $87,500 $88,500 $89,000 $89,500 $98,000 $98,500 $99,500\n",
      "Employee Related \n",
      "Expenses$5,500 $5,700 $8,200 $10,600 $10,700 $14,600 $14,700 $14,800 $14,900 $16,600 $16,700 $16,900\n",
      "Dues and \n",
      "Subscriptions$250 $300 $400 $500 $500 $500 $500 $650 $650 $750 $750 $750\n",
      "Legal Fees $5,000 $6,500 $7,500 $7,500 $10,000 $10,000 $10,000 $10,000 $12,500 $12,500 $12,500 $15,000\n",
      "Accounting Fees $1,500 $2,500 $2,500 $5,000 $5,000 $2,500 $2,500 $2,500 $2,500 $2,500 $2,500 $2,500\n",
      "Liability Insurance $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250\n",
      "Security\n",
      "Travel $1,250 $1,500 $1,750 $2,250 $2,500 $2,750 $3,000 $3,250 $3,500 $3,750 $4,000 $4,500\n",
      "Meals and \n",
      "Entertainment$2,000 $2,500 $5,000 $5,000 $7,500 $10,000 $15,000 $15,000 $15,000 $15,000 $15,000 $15,000\n",
      "Utilities $250 $250 $300 $350 $350 $400 $450 $500 $750 $1,000 $1,000 $1,250\n",
      "Telecommunicatio\n",
      "ns$500 $500 $500 $500 $500 $500 $500 $750 $750 $750 $750 $750\n",
      "Office Supplies $250 $250 $500 $750 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000\n",
      "Licensing\n",
      "Advertising and \n",
      "Promotion$5,000 $5,000 $7,500 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000\n",
      "Business Insurance $250 $250 $250 $250 $250 $250 $250 $250 $250 $250 $250 $250\n",
      "First Rule\n",
      "30\n",
      "CONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \n",
      "information and is shared only with the understanding that you will not share its contents or ideas with \n",
      "third parties without the express written consent of the plan author.Statements\n",
      "Projected Profit and Loss\n",
      "2023 2024 2025 2026 2027\n",
      "Revenue $1,966,976 $16,783,471 $45,155,399 $122,734,165\n",
      "Direct Costs $1,500 $157,750 $40,000 $80,000 $160,000\n",
      "Gross Margin ($1,500) $1,809,226 $16,743,471 $45,075,399 $122,574,165\n",
      "Gross Margin % 92% 100% 100% 100%\n",
      "Operating \n",
      "Expenses\n",
      "Salaries & \n",
      "Wages$59,000 $917,000 $1,714,000 $2,344,000 $2,944,000\n",
      "Employee \n",
      "Related \n",
      "Expenses$10,300 $149,900 $266,800 $372,800 $482,800\n",
      "Dues and \n",
      "Subscriptions$500 $6,500 $15,000 $25,000 $35,000\n",
      "Legal Fees $10,000 $119,000 $250,000 $350,000 $500,000\n",
      "Accounting Fees $34,000 $50,000 $75,000 $100,000\n",
      "Liability \n",
      "Insurance$2,000 $15,000 $25,000 $50,000 $100,000\n",
      "Security $50,000 $75,000 $100,000\n",
      "Travel $2,250 $34,000 $45,000 $75,000 $100,000\n",
      "Meals and \n",
      "Entertainment$3,750 $122,000 $200,000 $225,000 $250,000\n",
      "Utilities $550 $6,850 $7,500 $12,500 $15,000\n",
      "Telecommunica\n",
      "tions$7,250 $10,000 $15,000 $20,000\n",
      "Office Supplies $600 $9,750 $12,000 $25,000 $25,000\n",
      "Licensing\n",
      "Advertising and \n",
      "Promotion$107,500 $250,000 $500,000 $750,000\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjufa\\anaconda3\\envs\\vclone1\\lib\\site-packages\\langchain\\chains\\llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "llm = ChatAnthropic(temperature=0, model=\"claude-2\", anthropic_api_key=os.getenv(\"ANTHROPIC_KEY\"))\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\"What are the company's revenue targets in 2024?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"First Rule\\n24\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.• Staffing: Engineers, support, executives, and marketers will make up a \\nsubstantial part of operating expenses.\\n• Acquisitions: The purchases of Controlla.XYZ, Emvoice, and Suno.AI should \\nbe viewed as key strategic investments.\\nProfit Expectations\\nWe expect profitability to correlate with platform adoption, backing our brand \\nmessaging of being the new industry standard, and development of native and \\ndownstream marketing opportunities. Conservatively, we forecast running at a loss \\nfor 18–24 months, but with an aim to generate revenue as early as December of \\n2023.\\nIn summary, First Rule's projections indicate an innovative, opportunity-rich \\nventure poised for strategic growth. Aligning with industry trends and addressing \\nunmet needs positions us uniquely. Continuous revenue streams and one-off \\nopportunities create balance, supported by investment in ambassadorship and \\ntalent.\\nWhile challenging, First Rule's originality and fit with the current art and tech \\nlandscape make it a promising investment. Projections match trends and endorse a \\nmodel that resonates with stakeholders.\", metadata={'page': 24, 'source': 'first_rule.pdf'}),\n",
       " Document(page_content=\"First Rule\\n40\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret information and is shared only with the \\nunderstanding that you will not share its contents or ideas with third parties without the express written consent of the plan author.2024 Jan '24 Feb '24 Mar '24 Apr '24 May '24 June '24 July '24 Aug '24 Sept '24 Oct '24 Nov '24 Dec '24\\nTotal Revenue $1,750 $9,000 $11,000 $17,350 $26,278 $44,222 $112,907 $144,351 $190,077 $299,727 $386,568 $723,746\\nTotal Direct \\nCosts$8,750 $9,000 $9,500 $11,000 $12,000 $13,000 $14,500 $15,000 $15,500 $16,000 $16,500 $17,000\\nGross Margin ($7,000) $0 $1,500 $6,350 $14,278 $31,222 $98,407 $129,351 $174,577 $283,727 $370,068 $706,746\\nGross Margin % (400%) 0% 14% 37% 54% 71% 87% 90% 92% 95% 96% 98%\\nOperating \\nExpenses\\nSalaries and \\nWages$34,000 $42,500 $55,000 $67,000 $68,000 $87,500 $88,500 $89,000 $89,500 $98,000 $98,500 $99,500\\nEmployee Related \\nExpenses$5,500 $5,700 $8,200 $10,600 $10,700 $14,600 $14,700 $14,800 $14,900 $16,600 $16,700 $16,900\\nDues and \\nSubscriptions$250 $300 $400 $500 $500 $500 $500 $650 $650 $750 $750 $750\\nLegal Fees $5,000 $6,500 $7,500 $7,500 $10,000 $10,000 $10,000 $10,000 $12,500 $12,500 $12,500 $15,000\\nAccounting Fees $1,500 $2,500 $2,500 $5,000 $5,000 $2,500 $2,500 $2,500 $2,500 $2,500 $2,500 $2,500\\nLiability Insurance $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250 $1,250\\nSecurity\\nTravel $1,250 $1,500 $1,750 $2,250 $2,500 $2,750 $3,000 $3,250 $3,500 $3,750 $4,000 $4,500\\nMeals and \\nEntertainment$2,000 $2,500 $5,000 $5,000 $7,500 $10,000 $15,000 $15,000 $15,000 $15,000 $15,000 $15,000\\nUtilities $250 $250 $300 $350 $350 $400 $450 $500 $750 $1,000 $1,000 $1,250\\nTelecommunicatio\\nns$500 $500 $500 $500 $500 $500 $500 $750 $750 $750 $750 $750\\nOffice Supplies $250 $250 $500 $750 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000 $1,000\\nLicensing\\nAdvertising and \\nPromotion$5,000 $5,000 $7,500 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000 $10,000\\nBusiness Insurance $250 $250 $250 $250 $250 $250 $250 $250 $250 $250 $250 $250\", metadata={'page': 40, 'source': 'first_rule.pdf'}),\n",
       " Document(page_content='First Rule\\n30\\nCONFIDENTIAL - DO NOT DISSEMINATE. This business plan contains confidential, trade-secret \\ninformation and is shared only with the understanding that you will not share its contents or ideas with \\nthird parties without the express written consent of the plan author.Statements\\nProjected Profit and Loss\\n2023 2024 2025 2026 2027\\nRevenue $1,966,976 $16,783,471 $45,155,399 $122,734,165\\nDirect Costs $1,500 $157,750 $40,000 $80,000 $160,000\\nGross Margin ($1,500) $1,809,226 $16,743,471 $45,075,399 $122,574,165\\nGross Margin % 92% 100% 100% 100%\\nOperating \\nExpenses\\nSalaries & \\nWages$59,000 $917,000 $1,714,000 $2,344,000 $2,944,000\\nEmployee \\nRelated \\nExpenses$10,300 $149,900 $266,800 $372,800 $482,800\\nDues and \\nSubscriptions$500 $6,500 $15,000 $25,000 $35,000\\nLegal Fees $10,000 $119,000 $250,000 $350,000 $500,000\\nAccounting Fees $34,000 $50,000 $75,000 $100,000\\nLiability \\nInsurance$2,000 $15,000 $25,000 $50,000 $100,000\\nSecurity $50,000 $75,000 $100,000\\nTravel $2,250 $34,000 $45,000 $75,000 $100,000\\nMeals and \\nEntertainment$3,750 $122,000 $200,000 $225,000 $250,000\\nUtilities $550 $6,850 $7,500 $12,500 $15,000\\nTelecommunica\\ntions$7,250 $10,000 $15,000 $20,000\\nOffice Supplies $600 $9,750 $12,000 $25,000 $25,000\\nLicensing\\nAdvertising and \\nPromotion$107,500 $250,000 $500,000 $750,000', metadata={'page': 30, 'source': 'first_rule.pdf'})]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.similarity_search(\"What are the company's revenue targets in 2024?\", k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given context does not contain any information relevant to answering the question about what the president said regarding Ketanji Brown Jackson.\n",
      "No relevant information is found in the given context to answer the question about what the president said regarding Ketanji Brown Jackson.\n"
     ]
    }
   ],
   "source": [
    "for doc in compressed_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "BakeSpace Partner API Version 1.40  \n",
      " \n",
      "This document will outline the query structure for the BakeSpace partner API. The purpose is \n",
      "so that partners can retrieve bakespace recipe information for their display purposes.  \n",
      " \n",
      "The basic structure of a query is:  \n",
      " \n",
      "http://bakespace.com/api/query.php?pcode=<partner_code>&type=<type>&limit=<number>  \n",
      " \n",
      "where partner_code  is an alphanumeric string the partner is assigned by BakeSpace, type is \n",
      "the query type, and limit is how many results are to be returned.  \n",
      " \n",
      "Reply content type is XML and a typical replay structure is as follows:  \n",
      " \n",
      "<results>  \n",
      "   <count></count>  \n",
      "   <item> \n",
      "      <recipeid></recipeid>  \n",
      "      <name></name>  \n",
      "      <author></author>  \n",
      "      <chosendate></chosendate>  \n",
      "      <foodimg></foodimg>  \n",
      "      <thumbnailimg></thumbn ailimg> \n",
      "      <fullimg></fullimg>  \n",
      "      <desc></desc>  \n",
      "      <preptime></preptime>  \n",
      "      <cooktime></cooktime>  \n",
      "      <servings></servings>  \n",
      "      <directions></directions>  \n",
      "      <ingredients></ingredients>  \n",
      "   </item> \n",
      "   <item> \n",
      "        ... another recipe ...  \n",
      "   </item> \n",
      "</results>  \n",
      " \n",
      "Note that only the recipeoftheday  type will include the \"chosendate\" field in the reply.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Query parameter details for “type” are as follows:  \n",
      "Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1</cookbook_id>  \n",
      "  <title>Bob's Cookbook</title>  \n",
      "  <description>Bob made this cookbook one rainy sunday \n",
      "afternoon.</description>  \n",
      "  <cost>7.95</cost>  \n",
      "  <author_member_id>45783</author_member_id>  \n",
      "  <author_name />  \n",
      "  <author_member_img />  \n",
      "  <recipe_count>13</recipe_count>  \n",
      "  <location_created>Los Angeles, CA, USA</location_created>  \n",
      "  <language>English</language>  \n",
      "  <categories>Dessert, Beverage</categories>  \n",
      "  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \n",
      "  <videourl>http://www.youtube.com/?v=939djdj</videourl>  \n",
      "  <video_thumbnail />  \n",
      "  <facebook />  \n",
      "  <twitter />  \n",
      "  <recipes>  \n",
      "   <recipe>  \n",
      "    <recipe_id>1</recipe_id>  \n",
      "    <name>Spinach Di p</name>  \n",
      "    <summary>Tasty beyond belief, spinach is good for you also!</summary>  \n",
      "    <duration>13</duration>  \n",
      "    <servings>26</servings>  \n",
      "    <ingredients>2 cups Basil, 2 Tomatoes, 2 cups Spinach</ingredients>  \n",
      "    <equipment>1 Firehose</equipment>  \n",
      "    <directions>Cook it all up; serve hot</directions>  \n",
      "    <backstory>I made this once when I was a fireman back in \n",
      "Colorado.</backstory>  \n",
      "    <imgurl> </imgurl>  \n",
      "    <videourl> </videourl>  \n",
      "    <notes> </notes>  \n",
      "   </recipe>  \n",
      "   <recipe>  \n",
      "     ... \n",
      "   </recipe>  \n",
      "  </recipes> \n",
      " </item> \n",
      " \n",
      "Results Reply:  \n",
      "<results>  \n",
      " <item> \n",
      "  <cookbook_id>1</cookbook_id>  \n",
      "  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \n",
      "  <title>Sunday cooking</title>  \n",
      "  <description/>  \n",
      "  <cost>7.95</cost>  \n",
      "  <author_name/>  \n",
      "  <author_ member_id/>  \n",
      "  <videourl/>  \n",
      "  <video_thumbnail/>  \n",
      "  <recipe_count>13</recipe_count>  \n",
      "  <facebook/>  \n",
      "  <twitter/>  \n",
      "  <is_owned/>  \n",
      "  <downloads>5</downloads>  \n",
      " </item> \n",
      " <item> \n",
      "  ... \n",
      " </item> \n",
      "</results>  \n",
      " \n",
      "If the search type is “my”, then the XML will output recipe inf ormation instead of \n",
      "cookbook information, as follows:  \n",
      " \n",
      "<item> \n",
      " <recipe_id>49954</recipe_id>  \n",
      " <name>Angel Acres Baked Pineapple Pudding</name>  \n",
      " <author>angelacres</author>  \n",
      " <foodimg>4467a79f19383b25c9675153bb68253b.jpeg</foodimg>  \n",
      " \n",
      "<thumbnailimg>http://bake space.com/images/small/4467a79f19383b25c9675153bb6825\n",
      "3b.jpeg</thumbnailimg>  \n",
      " \n",
      "<imgurl>http://bakespace.com/images/small/4467a79f19383b25c9675153bb68253b.jpe\n",
      "g</imgurl>  \n",
      " \n",
      "<fullimg>http://bakespace.com/images/large/4467a79f19383b25c9675153bb68253b.jp\n",
      "eg</fullimg > \n",
      " \n",
      "Reply:  \n",
      "<results>  \n",
      "<item> \n",
      "<cookbook_id>1</cookbook_id>  \n",
      "<title>Bob's Cookbook</title>  \n",
      "<description>Bob made this cookbook one rainy sunday after noon.</description>  \n",
      "<imgurl/>  \n",
      "<cost>7.95</cost>  \n",
      "<author_member_id>45783</author_member_id>  \n",
      "<recipe_count>13</recipe_count>  \n",
      "<facebook/>  \n",
      "<twitter/>  \n",
      "<is_owned/>  \n",
      "<downloads/>  \n",
      "<top_downloads>  \n",
      " <download>  \n",
      "  <title>Jane's review</title>  \n",
      "  <imgurl>http://www.image sgalore.com/images/love.jpg</imgurl>  \n",
      "  <cost>3.95</cost>  \n",
      " </download>  \n",
      " <download>  \n",
      "   ... \n",
      " </download>  \n",
      "</top_downloads>  \n",
      "</item> \n",
      "</results>  \n",
      "329\n",
      "404\n",
      "373\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "for text in context:\n",
    "    print(text.page_content)\n",
    "\n",
    "text_list = [text.page_content for text in context]\n",
    "for text in text_list:\n",
    "    print(tiktoken_len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.organization = os.getenv(\"OPENAI_ORG\")\n",
    "\n",
    "def get_response(query):\n",
    "    context = vectorstore.similarity_search(query, k=4)\n",
    "    text_list = [text.page_content for text in context]\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : f\"\"\"You are a master programmer helping the user\n",
    "         craft API calls using the python requests library to the Bakespace API.  Bakespace\n",
    "         is a website for sharing recipes.  Reference the following context {text_list}\n",
    "         from the Bakespace API documentation to help the user craft their API call.\"\"\"},\n",
    "        {\"role\" : \"user\", \"content\" : query}\n",
    "    ]\n",
    "    models = [\"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-16k\"]\n",
    "    for model in models:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.9,\n",
    "            max_tokens=350,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0.6,\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "\n",
    "            return answer\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.bakespace.com/feeds/api_v2/latestRecipes\"\n",
    "params = {\n",
    "    \"limit\": 10,  # Optional parameter to limit the number of recipes returned\n",
    "    \"startrow\": 0  # Optional parameter to specify the starting row\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    recipes = response.text\n",
    "    # Do something with the recipes\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
      "    <meta name=\"description\" content=\"Explore 70,000+ recipes & indie cookbooks created by our community of home cooks. Join to share recipes & make your own cookbook.\">\n",
      "    <meta name=\"author\" content=\"\">\n",
      "    <meta name=\"google-site-verification\" content=\"qwPQWlO-5B13In_kLFS7e7YB8yaUmwzqqTRr-pKmU_U\" />\n",
      "    <link rel=\"icon\" href=\"/favicon.ico\">\n",
      "\n",
      "    <title>BakeSpace - Food community, recipes, cookbooks & cooking contests</title>\n",
      "\n",
      "    <!-- extra CSS -->\n",
      "    <link href=\"/bower_components/bootstrap/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
      "    <link href=\"/bower_components/font-awesome/css/font-awesome.min.css\" rel=\"stylesheet\">\n",
      "    <link href=\"/bower_components/ekko-lightbox/dist/ekko-lightbox.min.css\" rel=\"stylesheet\">\n",
      "    <link href=\"/bower_components/featherlight/release/featherlight.min.css\" rel=\"stylesheet\">\n",
      "    <link href=\"/assets/css/main.css\" rel=\"stylesheet\">\n",
      "    <link href=\"/assets/css/homepage-redesign.css\" rel=\"stylesheet\">\n",
      "\n",
      "\n",
      "    <link href=\"/assets/css/recipes.css\" rel=\"stylesheet\">\n",
      "    <link href=\"/assets/css/homepage-redesign.css\" rel=\"stylesheet\">\n",
      "\n",
      "</head>\n",
      "<body class=\"home\" >\n",
      "\n",
      "    <div class=\"pos-f-t\">\n",
      "\n",
      "\n",
      "\n",
      "<!--\n",
      "<script language=\"JavaScript\" type=\"text/javascript\" src=\"/_bsjs/wz_tooltip.js\"></script>\n",
      "<script src='http://cdn.wibiya.com/Toolbars/dir_0387/Toolbar_387256/Loader_387256.js' type='text/javascript'></script>\n",
      "-->\n",
      "\n",
      "\n",
      "<script src=\"https://connect.facebook.net/en_US/all.js\"></script>\n",
      "<script type=\"text/javascript\">\n",
      " FB.init({\n",
      "    appId  : '204620854407',\n",
      "    status : true, // check login status\n",
      "    cookie : true, // enable cookies to allow the server to access the session\n",
      "    oauth  : true // enable OAuth 2.0\n",
      "  });\n",
      "\n",
      "</script>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      <header>\n",
      "        <!-- Mobile Nav Bar -->\n",
      "        <nav class=\"navbar navbar-dark mobile-nav hidden-sm-up\">\n",
      "          <div class=\"row\">\n",
      "            <div class=\"float-xs-left\">\n",
      "\n",
      "              New to BakeSpace? <a href=\"/loginjoin\">Sign Up</a>\n",
      "            </div>\n",
      "            <div class=\"float-xs-right menu-button\">\n",
      "              <button class=\"\" type=\"button\" data-toggle=\"collapse\" data-target=\"#mobileMenu\" aria-controls=\"mobileMenu\" aria-expanded=\"false\" aria-label=\"Toggle navigation\">Menu <i class=\"fa fa-bars\"></i></button>\n",
      "            </div>\n",
      "          </div>\n",
      "        </nav>\n",
      "\n",
      "        <!-- Navigation Bar-->\n",
      "        <nav id=\"mainNav\" class=\"navbar navbar-light bg-white navbar-static-top\">\n",
      "          <div class=\"container-fluid\">\n",
      "            <div class=\"row\">\n",
      "              <div class=\"col-sm-3 nav-left pt-1 hidden-xs-down\">\n",
      "                <ul class=\"social-links\">\n",
      "                  <a href=\"https://instagram.com/bakespace\" target=\"_new\"><li class=\"social-instagram\"></li></a>\n",
      "                  <a href=\"https://facebook.com/bakespace\" target=\"_new\"><li class=\"social-facebook\"></li></a>\n",
      "                  <a href=\"https://twitter.com/bakespace\" target=\"_new\"><li class=\"social-twitter\"></li></a>\n",
      "                  <a href=\"https://pinterest.com/bakespace\" target=\"_new\"><li class=\"social-pinterest\"></li></a>\n",
      "                  <a href=\"https://plus.google.com/u/0/b/107315302504067014789/107315302504067014789/posts\" target=\"_new\"><li class=\"social-google\"></li></a>\n",
      "                </ul>\n",
      "              </div>\n",
      "              <div class=\"col-sm-6 nav-center text-xs-center\">\n",
      "                <div class=\"text-logo\">\n",
      "                  <a class=\"navbar-brand\" href=\"/\"><span>Bake</span>Space</a>\n",
      "                </div>\n",
      "                <div id=\"tagline\" class=\"text-slogan col-xs-12 fade in hidden-xs-down\">\n",
      "                  <span>Come for the food.</span> Stay for the conversation. ℠\n",
      "                </div>\n",
      "              </div>\n",
      "              <div class=\"col-sm-3 nav-right text-xs-right pt-1\">\n",
      "                <!--\n",
      "                <span class=\"logged-in text-xs-center\">\n",
      "                  <small><em>Hi,</em><br><a href=\"profile.html\">Babette!</a></small>\n",
      "                </span>\n",
      "                -->\n",
      "                <div class=\"login-area text-xs-right hidden-xs-down\">\n",
      "                  <div class=\"btn btn-search\" data-toggle=\"collapse\" data-target=\"#navbar-header\" aria-controls=\"navbar-header\" aria-expanded=\"false\" aria-label=\"Toggle navigation\"><i class=\"fa fa-search\"></i></div>\n",
      "                  <span class=\"person-icon\"><i class=\"fa fa-user\"></i></span>\n",
      "                  <a href=\"/loginjoin\">Sign in / Register</a>\n",
      "                </div>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "        </nav>\n",
      "\n",
      "        <!-- Secondary Navigation Bar-->\n",
      "        <nav class=\"navbar navbar-light bg-white navbar-static-top navbar-static-top-secondary hidden-xs-down\">\n",
      "          <div class=\"container\">\n",
      "            <div class=\"main-navigation\">\n",
      "              <ul class=\"nav\">\n",
      "                <li class=\"nav-collapse nav-item hidden-md-down\">\n",
      "                  <a class=\"nav-link\" href=\"/\"><i class=\"fa fa-2x fa-home\"></i></a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\" style=\"font-size:20px\">\n",
      "                  <a class=\"nav-link\" href=\"/cookbooks\">Cookbooks</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\" style=\"font-size:20px\">\n",
      "                  <a class=\"nav-link\" href=\"/recipes\">Recipes</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item hidden-md-down\" style=\"font-size:20px\">\n",
      "                  <a class=\"nav-link\" href=\"/cookbooks/cafe\">Make your own Cookbook</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\" style=\"font-size:20px\">\n",
      "                  <a class=\"nav-link\" href=\"https://bakespaceshop.com\" target=\"_new\">BakeCamp</a>\n",
      "                </li>\n",
      "              </ul>\n",
      "            </div>\n",
      "          </div>\n",
      "        </nav>\n",
      "\n",
      "        <div class=\"collapse  search-box\" id=\"navbar-header\">\n",
      "            <form action=\"/recipes/search/\" method=\"post\">\n",
      "          <div class=\"container bg-white p-1\">\n",
      "              <input type=\"text\" id=\"searchboxentry\" name='recipe_keywords' class=\"form-control\" placeholder=\"Search...\" maxlength=\"128\">\n",
      "              <a href=\"#\"><button type=\"submit\" class=\"btn\"><i class=\"fa fa-search\"></i></button></a>\n",
      "          </div>\n",
      "\t  <div style=\"text-align:center\">\n",
      "\t  \tSearch: \n",
      "\t  \t<input id=\"srch6\" name=\"new_search_bool_words\" value=\"ex\" type=\"radio\" checked> <label for=\"srch6\" style=\"color:#A4A4A4\">Exact</label>\n",
      "\t  \t<input id=\"srch2\" name=\"new_search_bool_words\" value=\"all\" type=\"radio\" > <label for=\"srch2\" style=\"color:#A4A4A4\">All</label>\n",
      "\t\t<input id=\"srch1\" name=\"new_search_bool_words\" value=\"any\" type=\"radio\" > <label for=\"srch1\" style=\"color:#A4A4A4\">Any of the words</label>\n",
      "\t\t&nbsp;\n",
      "\t\tAdd to Search:\n",
      "\t  \t<input id=\"srch3\" type=\"checkbox\" name=\"new_search_include_ingred\" value=\"1\"> <label for=\"srch3\" style=\"color:#A4A4A4\">Ingredients</label>\n",
      "\t  \t<input id=\"srch4\" type=\"checkbox\" name=\"new_search_include_descr\" value=\"1\"> <label for=\"srch4\" style=\"color:#A4A4A4\">Description</label>\n",
      "\t  \t<input id=\"srch5\" type=\"checkbox\" name=\"new_search_include_steps\" value=\"1\"> <label for=\"srch5\" style=\"color:#A4A4A4\">Instructions</label>\n",
      "\t  </div>\n",
      "            </form>\n",
      "        </div>\n",
      "\n",
      "    </header>\n",
      "\n",
      "    </div>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    <!-- Content Area -->\n",
      "    <div class=\"content\">\n",
      "\n",
      "\n",
      "      <!-- Mobile-only nav menu -->\n",
      "      <div class=\"collapse search-box\" id=\"mobileMenu\" aria-expanded=\"false\" style=\"\">\n",
      "        <div class=\"container\">\n",
      "          <ul class=\"nav navbar-nav\">\n",
      "            <li class=\"nav-item\">\n",
      "              <a class=\"nav-link\" href=\"/feed\">What's New</a>\n",
      "            </li>\n",
      "            <li class=\"nav-item\">\n",
      "              <a class=\"nav-link\" href=\"/recipes\">Search Recipes</a>\n",
      "            </li>\n",
      "            <li class=\"nav-item\">\n",
      "              <a class=\"nav-link\" href=\"/cookbooks\">Browse Cookbooks</a>\n",
      "            </li>\n",
      "            <li class=\"nav-item\">\n",
      "              <a class=\"nav-link\" href=\"/cookbookclub\">Contests</a>\n",
      "            </li>\n",
      "            <li class=\"nav-item\">\n",
      "              <a class=\"nav-link\" href=\"/cookbooks/cafe/\">Make Your Own Cookbook</a>\n",
      "            </li>\n",
      "            <li class=\"nav-item\">\n",
      "              <a class=\"nav-link\" href=\"https://bakespaceshop.com\">BakeCamp</a>\n",
      "            </li>\n",
      "            <li class=\"nav-item\">\n",
      "              <a class=\"nav-link\" href=\"/loginjoin/aboutus\">About Bakespace</a>\n",
      "            </li>\n",
      "            <li class=\"nav-sub-item\">\n",
      "              <a class=\"nav-link\" href=\"/loginjoin\">Login</a>\n",
      "            </li>\n",
      "            <li class=\"nav-sub-item\">\n",
      "              <a class=\"nav-link\" href=\"/loginjoin\">Create Account</a>\n",
      "            </li>\n",
      "            <li class=\"nav-item text-xs-center\">\n",
      "              <ul class=\"social-links\" style=\"width:160px; margin: 20px auto\">\n",
      "                <a href=\"https://instagram.com/bakespace\" target=\"_new\"><li class=\"social-instagram\"></li></a>\n",
      "                <a href=\"https://facebook.com/bakespace\" target=\"_new\"><li class=\"social-facebook\"></li></a>\n",
      "                <a href=\"https://twitter.com/bakespace\" target=\"_new\"><li class=\"social-twitter\"></li></a>\n",
      "                <a href=\"https://pinterest.com/bakespace\" target=\"_new\"><li class=\"social-pinterest\"></li></a>\n",
      "                <a href=\"https://plus.google.com/u/0/b/107315302504067014789/107315302504067014789/posts\" target=\"_new\"><li class=\"social-google\"></li></a>\n",
      "              </ul>\n",
      "            </li>\n",
      "          </ul>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      <!-- Member Recipes Row -->\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row mb-2\">\n",
      "          <div class=\"col-md-3 col-sm-6\">\n",
      "            <h4 class=\"category-title\">Member Recipes</h4>\n",
      "          </div>\n",
      "          <div class=\"text-slogan col-md-6 text-xs-center hidden-sm-down\">\n",
      "            <span>Come for the food.</span> Stay for the conversation. ℠\n",
      "          </div>\n",
      "          <div class=\"text-start-here col-md-3 col-sm-6 text-xs-right hidden-sm-down\">\n",
      "            New<span class=\"hidden-lg-down\"> to BakeSpace</span>? <a href=\"/loginjoin/aboutus/\"><strong>Start Here.</strong></a>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"recipes row\">\n",
      "          <div class=\"col-md-3 col-xs-6\">\n",
      "            <a href=\"/recipes/tag/featured/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/3.png\" class=\"img-fluid\" alt=\"Savory Recipes\">\n",
      "            </a>\n",
      "            <h5>Savory Recipes</h5>\n",
      "            <p class=\"hidden-xs-down\">Dinner is served! From our table to yours</p>\n",
      "          </div>\n",
      "          <div class=\"col-md-3 col-xs-6 mb-2\">\n",
      "            <a href=\"/recipes/tag/trending/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/9.png\" class=\"img-fluid\" alt=\"Something Sweet\">\n",
      "            </a>\n",
      "            <h5>Something Sweet</h5>\n",
      "            <p class=\"hidden-xs-down\">Satisfy your sweet tooth</p>\n",
      "          </div>\n",
      "          <div class=\"col-md-3 col-xs-6\">\n",
      "            <a href=\"/recipes/browse\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/2.png\" class=\"img-fluid\" alt=\"Seasonal Recipes\">\n",
      "            </a>\n",
      "            <h5>Browse All Recipes</h5>\n",
      "            <p class=\"hidden-xs-down\">Looking for something specific? Browse by categories</p>\n",
      "          </div>\n",
      "          <div class=\"col-md-3 col-xs-6\">\n",
      "            <a href=\"/members/profile/Home_Economics/1137580/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/home_econ_recipe_of_day.png\" class=\"img-fluid\" alt=\"Recipe of the Day\">\n",
      "            </a>\n",
      "            <h5>Eat Famously</h5>\n",
      "            <p class=\"hidden-xs-down\">Recipes from our favorite new show</p>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "      <hr>\n",
      "\n",
      "      <!-- Member Cookbooks Row -->\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row mb-2\">\n",
      "          <div class=\"col-md-3 col-sm-6\">\n",
      "            <h4 class=\"category-title\">Member Cookbooks</h4>\n",
      "          </div>\n",
      "          <div class=\"text-slogan col-md-6 text-xs-center hidden-sm-down\">\n",
      "          </div>\n",
      "          <div class=\"text-start-here col-md-3 col-sm-6 text-xs-right hidden-sm-down\">\n",
      "            <a href=\"/cookbooks/\">Search Cookbooks</a>\n",
      "          </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cookbooks row\">\n",
      "\n",
      "          <div class=\"col-md-3 col-xs-6\">\n",
      "            <a href=\"/cookbooks/detail/ABC%E2%80%99s-Home-Economics%3A-Hayworth-Family-Cookbook/5132/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/abc_home_econ_cookbook.jpg\" class=\"img-fluid\" alt=\"Home-Econ Cookbook\">\n",
      "            </a>\n",
      "            <h5>ABC's Home Economics Cookbook</h5>\n",
      "            <p class=\"hidden-xs-down\">a BakeSpace Exclusive</p>\n",
      "          </div>\n",
      "\n",
      "          <div class=\"col-md-3 col-xs-6 mb-2\">\n",
      "            <a href=\"/cookbooks/tag/bestsellers/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/best-selling-cookbooks.jpg\" class=\"img-fluid\" alt=\"Best-selling Cookbooks\">\n",
      "            </a>\n",
      "            <h5>Best-selling Cookbooks</h5>\n",
      "            <p class=\"hidden-xs-down\">Indie Authors</p>\n",
      "          </div>\n",
      "\n",
      "          <div class=\"col-md-3 col-xs-6\">\n",
      "            <a href=\"/cookbooks/tag/newest/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/6.png\" class=\"img-fluid\" alt=\"New Cookbooks\">\n",
      "            </a>\n",
      "            <h5>New Cookbooks</h5>\n",
      "            <p class=\"hidden-xs-down\">Discover your new favorite recipes in our one-of-a-kind Cookbooks</p>\n",
      "          </div>\n",
      "\n",
      "          <div class=\"col-md-3 col-xs-6\">\n",
      "            <a href=\"/cookbooks/cafe/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/8.png\" class=\"img-fluid\" alt=\"Make Your Own Cookbook\">\n",
      "            </a>\n",
      "            <h5>Make Your Own Cookbook</h5>\n",
      "            <p class=\"hidden-xs-down\">Make that cookbook you've been dreaming of! It's quick, easy &amp; free!</p>\n",
      "          </div>\n",
      "\n",
      "\n",
      "        </div>\n",
      "      </div>\n",
      "      <hr>\n",
      "\n",
      "      <!-- Events & Member News Row -->\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row mb-2\">\n",
      "          <div class=\"col-xs-12\">\n",
      "            <h4 class=\"category-title\">Events &amp; Member News</h4>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"events row\">\n",
      "          <div class=\"event col-md-3 col-xs-6\">\n",
      "            <a href=\"/cookbookclub/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/11.png\" class=\"img-fluid\" alt=\"Featured Contest\">\n",
      "            </a>\n",
      "            <h5><span class=\"hidden-xs-down\">Join Our </span><span class=\"hidden-sm-down\">Monthly</span> Cookbook Club</h5>\n",
      "            <p class=\"hidden-sm-down\">Every month we'll create a new cookbook together!</p>\n",
      "          </div>\n",
      "          <div class=\"event col-md-3 col-xs-6\">\n",
      "            <a href=\"https://bakespaceshop.com\" class=\"image-thumb-overlay\" target=\"_new\">\n",
      "              <img src=\"./Bakespace_files/1.png\" class=\"img-fluid\" alt=\"Upcoming Events\">\n",
      "            </a>\n",
      "            <h5>Up your Baking Game</h5>\n",
      "            <p class=\"hidden-sm-down\">Shop BakeSpace</p>\n",
      "          </div>\n",
      "          <div class=\"event col-md-3 col-xs-6\">\n",
      "            <a href=\"/members/top100/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/10.png\" class=\"img-fluid\" alt=\"Connect with home cooks around the world\">\n",
      "            </a>\n",
      "            <h5>Connect with Home Cooks Around the Globe</h5>\n",
      "            <p class=\"hidden-sm-down\">Check out our most active members</p>\n",
      "          </div>\n",
      "          <div class=\"event col-md-3 col-xs-6\">\n",
      "            <a href=\"/loginjoin/aboutus/\" class=\"image-thumb-overlay\">\n",
      "              <img src=\"./Bakespace_files/welcome.jpg\" class=\"img-fluid\" alt=\"Welcome to Bakespace\">\n",
      "            </a>\n",
      "            <h5>New to Bakespace?</h5>\n",
      "            <p class=\"hidden-sm-down\">Learn about our humble beginnings and connect with our founder</p>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "\n",
      "    <!-- Newsletter signup -->\n",
      "    <div class=\"newsletter-signup\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-sm-5\">\n",
      "            <span>Get BakeSpace in your Inbox</span><br>\n",
      "            <small>Subscribe and be the first to hear about news &amp; updates sent to your inbox.</small>\n",
      "          </div>\n",
      "          <div class=\"col-sm-7 search-form form-group\">\n",
      "            <form action=\"https://bakespace.us1.list-manage.com/subscribe/post?u=5be72ecce8377b0bace6706a6&amp;id=b0daff2e79\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n",
      "              <input type=\"email\" value=\"\" name=\"EMAIL\" class=\"form-control input-block\" id=\"mce-EMAIL\" placeholder=\"Your email address\">\n",
      "              <div id=\"mce-responses\">\n",
      "                <div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\n",
      "                <div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\n",
      "              </div><!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\n",
      "              <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_5be72ecce8377b0bace6706a6_b0daff2e79\" tabindex=\"-1\" value=\"\"></div>\n",
      "              <button type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"btn btn-signup btn-danger\">Sign Me Up <i class=\"fa fa-arrow-circle-o-right\"></i></button>\n",
      "            </form>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div>\n",
      "    <!-- /Newsletter signup -->\n",
      "\n",
      "\n",
      "\n",
      "    <!-- Footer -->\n",
      "    <footer>\n",
      "      <nav class=\"navbar-light\">\n",
      "        <div class=\"container\">\n",
      "          <div class=\"row\">\n",
      "            <div class=\"col-md-6\">\n",
      "              <ul class=\"nav navbar-nav\">\n",
      "                <li class=\"nav-item\">\n",
      "                  <a class=\"nav-link\" href=\"/loginjoin/aboutus\">About</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\">\n",
      "                  <a class=\"nav-link\" href=\"/more/faq\">FAQ</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\">\n",
      "                  <a class=\"nav-link\" href=\"/recipes/browse\">Recipe Archive</a>\n",
      "                </li>\n",
      "              </ul>\n",
      "            </div>\n",
      "            <div class=\"col-md-6 text-xs-right pt-2\">\n",
      "              <a href=\"/recipes/submit\" class=\"btn btn-add btn-primary\" style=\"margin-bottom:10px;\"><i class=\"fa fa-plus\"></i> Add Recipe</a>\n",
      "              <a href=\"/cookbooks/submit\" class=\"btn btn-add btn-primary\" style=\"margin-bottom:10px;\"><i class=\"fa fa-plus\"></i> Add Cookbook</a>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </nav>\n",
      "\n",
      "      <div class=\"footer-bottom\">\n",
      "        <div class=\"container\">\n",
      "          <div class=\"row\">\n",
      "            <div class=\"col-sm-6\">\n",
      "              <small>&copy; 2006 - 2023 BakeSpace, Inc. All Rights Reserved.</small>\n",
      "            </div>\n",
      "            <div class=\"col-sm-6\">\n",
      "              <div class=\"app-store float-xs-left\">\n",
      "                <img src=\"/assets/images/app-store.svg\" class=\"img-fluid\" alt=\"Available on the App Store\" />\n",
      "              </div>\n",
      "              <div class=\"join-community\">\n",
      "                <strong>Join Our <span class=\"hidden-md\">Awesome</span><br>Community.</strong>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "    </footer>\n",
      "\n",
      "\n",
      "<!-- google analytics -->\n",
      "<script>\n",
      "  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n",
      "  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n",
      "  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n",
      "  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n",
      "  ga('create', 'UA-5278656-1', 'auto');\n",
      "  ga('send', 'pageview');\n",
      "</script>\n",
      "<!-- google analytics -->\n",
      "\n",
      "    <!-- Bootstrap core JavaScript\n",
      "    ================================================== -->\n",
      "    <!-- Placed at the end of the document so the pages load faster -->\n",
      "    <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.0.0/jquery.min.js?v=2\" integrity=\"sha384-THPy051/pYDQGanwU6poAc/hOdQxjnOEXzbT+OuUAFqNqFjL+4IGLBgCJC3ZOShY\" crossorigin=\"anonymous\"></script>\n",
      "    <script>window.jQuery || document.write('<script src=\"/bower_components/jquery/dist/jquery.min.js?v=2\"><\\/script>')</script>\n",
      "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/tether/1.2.0/js/tether.min.js?v=2\" integrity=\"sha384-Plbmg8JY28KFelvJVai01l8WyZzrYWG825m+cZ0eDDS1f7d/js6ikvy1+X+guPIB\" crossorigin=\"anonymous\"></script>\n",
      "    <script src=\"/bower_components/bootstrap/dist/js/bootstrap.min.js?v=2\"></script>\n",
      "    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->\n",
      "    <script src=\"/assets/js/ie10-viewport-bug-workaround.js?v=2\"></script>\n",
      "    <!-- Other component js -->\n",
      "    <script src=\"/bower_components/ekko-lightbox/dist/ekko-lightbox.min.js?v=2\"></script>\n",
      "    <script src=\"/bower_components/featherlight/release/featherlight.min.js\"></script>\n",
      "    <!-- Main .JS -->\n",
      "    <script src=\"/assets/js/main.js?v=5\"></script>\n",
      "    <script src=\"/assets/js/home.js?v=1\"></script>\n",
      "\n",
      "\n",
      "<script>\n",
      "  window.intercomSettings = {\n",
      "    app_id: \"m5x07gaj\"\n",
      "  };\n",
      "</script>\n",
      "\n",
      "<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='https://widget.intercom.io/widget/m5x07gaj';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}}})()</script>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(recipes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = get_response(\"I want to create a javascript and html frontend that will\\\n",
    "    display a Bakespace user's recipe on the page and then pass the recipe information to an\\\n",
    "    API that will store then give the recipe to an LLM as context to answer any\\\n",
    "    questions the user may have about the recipe via an expandable chat bubble\\\n",
    "        in the bottom right hand corner of the web page.  Can you help me code snippets\\\n",
    "            assuming the LLM takes in the recipep text as a string and a user\\\n",
    "                question as a string?  A unique session_id should be created and\\\n",
    "                    passed to the api endpoint as well when making the POST after\\\n",
    "                        the user submits their question about the recipe in the\\\n",
    "                            expandable chat bubble.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the answer to a new text file\n",
    "with open(\"answer.txt\", \"w\") as f:\n",
    "    f.write(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Replace <your_api_key> in openai_api_key=\"<your_api_key>\" with your actual OpenAI key.\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "python_executor = create_python_agent(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    agent_executor_kwargs={\"handle_parsing_errors\": True},\n",
    ")\n",
    "\n",
    "def get_context(query):\n",
    "    context = vectorstore.similarity_search(query, k=4)\n",
    "    return [context.page_content for context in context]\n",
    "\n",
    "# Define a list of tools offered by the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Python REPL Tool\",\n",
    "        func=python_executor.run,\n",
    "        description=\"Useful for running Python code in a REPL.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Query Bakespace API Docs\",\n",
    "        func=get_context,\n",
    "        description=\"Useful for querying the Bakespace API docs.\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Query Bakespace API Docs` with `{'tool_input': 'load user information'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[\"Reply:  \\n<results>  \\n <item> \\n  <author>Bob Jones</author>  \\n  <author_member_id>12</author_member_id>  \\n  <author_facebook>http://facebook.com/myusername</author _facebook>  \\n  <author_twitter>http://twitter.com/myusername</author_twitter>  \\n  <about>Bob is from a small town and likes cats. He likes all kind of \\ncats.</about>  \\n </item> \\n</results>  \\n \\n \\n \\ntype:  getCookbookProfile  \\n \\nDescription:  \\nReturns details of a specified c ookbook.  \\n \\nParameters:  \\ncookbookid : required  \\n \\nReply:  \\n<results>  \\n <item> \\n  <cookbook_id>1</cookbook_id>  \\n  <title>Bob's Cookbook</title>  \\n  <description>Bob made this cookbook one rainy sunday \\nafternoon.</description>  \\n  <cost>7.95</cost>  \\n  <overall_rating />  \\n  <author_name>Bob Jones</author_name>  \\n  <author_member_id>45783</author_member_id>  \\n  \\n<author_member_img>http://bakespace.com/images/normal/xxxx.jpg</author_member_\\nimg> \\n  <recipe_count>13</recipe_count>  \\n  <location_created>Los Angeles, CA, USA</location_creat ed> \\n  <language>English</language>  \\n  <categories>Dessert, Beverage</categories>  \\n  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \\n  <videourl>http://www.youtube.com/?v=939djdj</videourl>  \", \" \\nReply:  \\n<results>  \\n<item> \\n<cookbook_id>1</cookbook_id>  \\n<title>Bob's Cookbook</title>  \\n<description>Bob made this cookbook one rainy sunday after noon.</description>  \\n<imgurl/>  \\n<cost>7.95</cost>  \\n<author_member_id>45783</author_member_id>  \\n<recipe_count>13</recipe_count>  \\n<facebook/>  \\n<twitter/>  \\n<is_owned/>  \\n<downloads/>  \\n<top_downloads>  \\n <download>  \\n  <title>Jane's review</title>  \\n  <imgurl>http://www.image sgalore.com/images/love.jpg</imgurl>  \\n  <cost>3.95</cost>  \\n </download>  \\n <download>  \\n   ... \\n </download>  \\n</top_downloads>  \\n</item> \\n</results>  \", 'Result Reply:  \\n<results>  \\n<sid>dxBKecejS1b41VVmqHp97fOnwYKXS2zf</sid>  \\n</results>  \\n \\n \\n \\ntype:  logout  \\n \\nDescription:  \\nAllows a user to sign out which clears the appropriate cookies.  \\n \\nParameters:  \\nNone \\n \\nReplies:  \\n<results>  \\n<result>Success</result>  \\n</results>  \\n \\n \\n \\n ', ' \\nResults Reply:  \\n<results>  \\n <item> \\n  <cookbook_id>1</cookbook_id>  \\n  <cover_imgurl>http://www.imagesgalore.com/images/mycover.jpg</cover_imgurl>  \\n  <title>Sunday cooking</title>  \\n  <description/>  \\n  <cost>7.95</cost>  \\n  <author_name/>  \\n  <author_ member_id/>  \\n  <videourl/>  \\n  <video_thumbnail/>  \\n  <recipe_count>13</recipe_count>  \\n  <facebook/>  \\n  <twitter/>  \\n  <is_owned/>  \\n  <downloads>5</downloads>  \\n </item> \\n <item> \\n  ... \\n </item> \\n</results>  \\n \\nIf the search type is “my”, then the XML will output recipe inf ormation instead of \\ncookbook information, as follows:  \\n \\n<item> \\n <recipe_id>49954</recipe_id>  \\n <name>Angel Acres Baked Pineapple Pudding</name>  \\n <author>angelacres</author>  \\n <foodimg>4467a79f19383b25c9675153bb68253b.jpeg</foodimg>  \\n \\n<thumbnailimg>http://bake space.com/images/small/4467a79f19383b25c9675153bb6825\\n3b.jpeg</thumbnailimg>  \\n \\n<imgurl>http://bakespace.com/images/small/4467a79f19383b25c9675153bb68253b.jpe\\ng</imgurl>  \\n \\n<fullimg>http://bakespace.com/images/large/4467a79f19383b25c9675153bb68253b.jp\\neg</fullimg > ']\u001b[0m"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "'Query Bakespace API Docs' does not match '^[a-zA-Z0-9_-]{1,64}$' - 'messages.3.name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m mrkl \u001b[39m=\u001b[39m initialize_agent(\n\u001b[0;32m      2\u001b[0m     tools, llm, agent\u001b[39m=\u001b[39mAgentType\u001b[39m.\u001b[39mOPENAI_MULTI_FUNCTIONS, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 4\u001b[0m code \u001b[39m=\u001b[39m mrkl\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mHow can I load a specific user\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms information from the Bakespace API?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:487\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    486\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    488\u001b[0m         _output_key\n\u001b[0;32m    489\u001b[0m     ]\n\u001b[0;32m    491\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    493\u001b[0m         _output_key\n\u001b[0;32m    494\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    293\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    294\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    296\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    281\u001b[0m     inputs,\n\u001b[0;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    285\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    287\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    288\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    289\u001b[0m     )\n\u001b[0;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\agents\\agent.py:1039\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1039\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m   1040\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1041\u001b[0m         color_mapping,\n\u001b[0;32m   1042\u001b[0m         inputs,\n\u001b[0;32m   1043\u001b[0m         intermediate_steps,\n\u001b[0;32m   1044\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m   1045\u001b[0m     )\n\u001b[0;32m   1046\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1047\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m   1048\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m   1049\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\agents\\agent.py:836\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    833\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m    835\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 836\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mplan(\n\u001b[0;32m    837\u001b[0m         intermediate_steps,\n\u001b[0;32m    838\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    839\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[0;32m    840\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    842\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\agents\\openai_functions_multi_agent\\base.py:269\u001b[0m, in \u001b[0;36mOpenAIMultiFunctionsAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mformat_prompt(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m    268\u001b[0m messages \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mto_messages()\n\u001b[1;32m--> 269\u001b[0m predicted_message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mpredict_messages(\n\u001b[0;32m    270\u001b[0m     messages, functions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctions, callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    271\u001b[0m )\n\u001b[0;32m    272\u001b[0m agent_decision \u001b[39m=\u001b[39m _parse_ai_message(predicted_message)\n\u001b[0;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m agent_decision\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:601\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m     _stop \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stop)\n\u001b[1;32m--> 601\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(messages, stop\u001b[39m=\u001b[39m_stop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:551\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    545\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    546\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    550\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 551\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    552\u001b[0m         [messages], stop\u001b[39m=\u001b[39mstop, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    553\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m    554\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    555\u001b[0m         \u001b[39mreturn\u001b[39;00m generation\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[0;32m    308\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 309\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    310\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[0;32m    311\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[0;32m    312\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[0;32m    313\u001b[0m ]\n\u001b[0;32m    314\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:299\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[0;32m    297\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 299\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    300\u001b[0m                 m,\n\u001b[0;32m    301\u001b[0m                 stop\u001b[39m=\u001b[39mstop,\n\u001b[0;32m    302\u001b[0m                 run_manager\u001b[39m=\u001b[39mrun_managers[i] \u001b[39mif\u001b[39;00m run_managers \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    303\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    304\u001b[0m             )\n\u001b[0;32m    305\u001b[0m         )\n\u001b[0;32m    306\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    307\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:446\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    443\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(\n\u001b[0;32m    447\u001b[0m         messages, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    448\u001b[0m     )\n\u001b[0;32m    449\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\openai.py:345\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    344\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m--> 345\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    346\u001b[0m     messages\u001b[39m=\u001b[39mmessage_dicts, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    348\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\openai.py:278\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 278\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\openai.py:276\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: 'Query Bakespace API Docs' does not match '^[a-zA-Z0-9_-]{1,64}$' - 'messages.3.name'"
     ]
    }
   ],
   "source": [
    "mrkl = initialize_agent(\n",
    "    tools, llm, agent=AgentType.OPENAI_MULTI_FUNCTIONS, verbose=True\n",
    ")\n",
    "code = mrkl.run(\"How can I load a specific user's information from the Bakespace API?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_organization=openai_org,\n",
    ")\n",
    "\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field, namespace=\"documentation\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I create a multi-tool agent using the langchain library?\"\n",
    "\n",
    "answers = vectorstore.similarity_search(\n",
    "    namespace=\"documentation\",\n",
    "    query=query,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"Agent toolkits.\"\"\"\n",
      "\n",
      "from langchain.agents.agent_toolkits.azure_cognitive_services.toolkit import (\n",
      "    AzureCognitiveServicesToolkit,\n",
      ")\n",
      "from langchain.agents.agent_toolkits.csv.base import create_csv_agent\n",
      "from langchain.agents.agent_toolkits.file_management.toolkit import (\n",
      "    FileManagementToolkit,\n",
      ")\n",
      "from langchain.agents.agent_toolkits.gmail.toolkit import GmailToolkit\n",
      "from langchain.agents.agent_toolkits.jira.toolkit import JiraToolkit\n",
      "from langchain.agents.agent_toolkits.json.base import create_json_agent\n",
      "from langchain.agents.agent_toolkits.json.toolkit import JsonToolkit\n",
      "from langchain.agents.agent_toolkits.nla.toolkit import NLAToolkit\n",
      "from langchain.agents.agent_toolkits.office365.toolkit import O365Toolkit\n",
      "from langchain.agents.agent_toolkits.openapi.base import create_openapi_agent\n",
      "from langchain.agents.agent_toolkits.openapi.toolkit import OpenAPIToolkit\n",
      "from langchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
      "from langchain.agents.agent_toolkits.playwright.toolkit import PlayWrightBrowserToolkit\n",
      "from langchain.agents.agent_toolkits.powerbi.base import create_pbi_agent\n",
      "from langchain.agents.agent_toolkits.powerbi.chat_base import create_pbi_chat_agent\n",
      "from langchain.agents.agent_toolkits.powerbi.toolkit import PowerBIToolkit\n",
      "from langchain.agents.agent_toolkits.python.base import create_python_agent\n",
      "from langchain.agents.agent_toolkits.spark.base import create_spark_dataframe_agent\n",
      "from langchain.agents.agent_toolkits.spark_sql.base import create_spark_sql_agent\n",
      "from langchain.agents.agent_toolkits.spark_sql.toolkit import SparkSQLToolkit\n",
      "from langchain.agents.agent_toolkits.sql.base import create_sql_agent\n",
      "from langchain.agents.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
      "from langchain.agents.agent_toolkits.vectorstore.base import (\n",
      "    create_vectorstore_agent,\n",
      "    create_vectorstore_router_agent,\n",
      ")\n",
      "from langchain.agents.agent_toolkits.vectorstore.toolkit import (\n",
      "    VectorStoreInfo,\n",
      "    VectorStoreRouterToolkit,\n",
      "    VectorStoreToolkit,\n",
      ")\n",
      "from langchain.agents.agent_toolkits.zapier.toolkit import ZapierToolkit\n",
      "\n",
      "__all__ = [\n",
      "    \"create_json_agent\",\n",
      "    \"create_sql_agent\",\n",
      "    \"create_openapi_agent\",\n",
      "    \"create_pbi_agent\",\n",
      "    \"create_pbi_chat_agent\",\n",
      "    \"create_python_agent\",\n",
      "    \"create_vectorstore_agent\",\n",
      "    \"JsonToolkit\",\n",
      "    \"SQLDatabaseToolkit\",\n",
      "    \"SparkSQLToolkit\",\n",
      "    \"NLAToolkit\",\n",
      "    \"PowerBIToolkit\",\n",
      "    \"OpenAPIToolkit\",\n",
      "    \"VectorStoreToolkit\",\n",
      "    \"create_vectorstore_router_agent\",\n",
      "    \"VectorStoreInfo\",\n",
      "    \"VectorStoreRouterToolkit\",\n",
      "    \"create_pandas_dataframe_agent\",\n",
      "    \"create_spark_dataframe_agent\",\n",
      "    \"create_spark_sql_agent\",\n",
      "    \"create_csv_agent\",\n",
      "    \"ZapierToolkit\",\n",
      "    \"GmailToolkit\",\n",
      "    \"JiraToolkit\",\n",
      "    \"FileManagementToolkit\",\n",
      "    \"PlayWrightBrowserToolkit\",\n",
      "    \"AzureCognitiveServicesToolkit\",\n",
      "    \"O365Toolkit\",\n",
      "]\n",
      "\"\"\"OpenAPI spec agent.\"\"\"\n",
      "from typing import Any, Dict, List, Optional\n",
      "\n",
      "from langchain.agents.agent import AgentExecutor\n",
      "from langchain.agents.agent_toolkits.openapi.prompt import (\n",
      "    OPENAPI_PREFIX,\n",
      "    OPENAPI_SUFFIX,\n",
      ")\n",
      "from langchain.agents.agent_toolkits.openapi.toolkit import OpenAPIToolkit\n",
      "from langchain.agents.mrkl.base import ZeroShotAgent\n",
      "from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "from langchain.callbacks.base import BaseCallbackManager\n",
      "from langchain.chains.llm import LLMChain\n",
      "\n",
      "\n",
      "def create_openapi_agent(\n",
      "    llm: BaseLanguageModel,\n",
      "    toolkit: OpenAPIToolkit,\n",
      "    callback_manager: Optional[BaseCallbackManager] = None,\n",
      "    prefix: str = OPENAPI_PREFIX,\n",
      "    suffix: str = OPENAPI_SUFFIX,\n",
      "    format_instructions: str = FORMAT_INSTRUCTIONS,\n",
      "    input_variables: Optional[List[str]] = None,\n",
      "    max_iterations: Optional[int] = 15,\n",
      "    max_execution_time: Optional[float] = None,\n",
      "    early_stopping_method: str = \"force\",\n",
      "    verbose: bool = False,\n",
      "    return_intermediate_steps: bool = False,\n",
      "    agent_executor_kwargs: Optional[Dict[str, Any]] = None,\n",
      "    **kwargs: Dict[str, Any],\n",
      ") -> AgentExecutor:\n",
      "    \"\"\"Construct a json agent from an LLM and tools.\"\"\"\n",
      "    tools = toolkit.get_tools()\n",
      "    prompt = ZeroShotAgent.create_prompt(\n",
      "        tools,\n",
      "        prefix=prefix,\n",
      "        suffix=suffix,\n",
      "        format_instructions=format_instructions,\n",
      "        input_variables=input_variables,\n",
      "    )\n",
      "    llm_chain = LLMChain(\n",
      "        llm=llm,\n",
      "        prompt=prompt,\n",
      "        callback_manager=callback_manager,\n",
      "    )\n",
      "    tool_names = [tool.name for tool in tools]\n",
      "    agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names, **kwargs)\n",
      "    return AgentExecutor.from_agent_and_tools(\n",
      "        agent=agent,\n",
      "        tools=tools,\n",
      "        callback_manager=callback_manager,\n",
      "        verbose=verbose,\n",
      "        return_intermediate_steps=return_intermediate_steps,\n",
      "        max_iterations=max_iterations,\n",
      "        max_execution_time=max_execution_time,\n",
      "        early_stopping_method=early_stopping_method,\n",
      "        **(agent_executor_kwargs or {}),\n",
      "    )\n",
      "\"\"\"An agent designed to hold a conversation in addition to using tools.\"\"\"\n"
     ]
    }
   ],
   "source": [
    "for answer in answers:\n",
    "    print(answer.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What are the highlights of next year's revenue projections?\"\n",
    "context = vectorstore.similarity_search(\n",
    "    query=user_question,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples from the context\n",
    "context_list = [(doc.page_content, doc.metadata['source'], doc.metadata['page']) for doc in context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the page content from the context\n",
    "context_page_content = [doc[0] for doc in context_list]\n",
    "\n",
    "def get_bplan_response(question: str, context: list):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \"content\": f\"\"\"You are a master busines advisor\n",
    "            and start-up strategist answering a question {question} about \n",
    "            an early stage company's business plan.  The relevant information\n",
    "            from the business plan is {context}.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": f\"\"\"Please answer my {question} about the \n",
    "            business plan.\"\"\"\n",
    "        },\n",
    "    ]\n",
    "    models = [\"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-0613, gpt-3.5-turbo\"] # Set list of models to iterate through\n",
    "    for model in models:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages = messages,\n",
    "                max_tokens=500,\n",
    "                frequency_penalty=0.5,\n",
    "                presence_penalty=0.5,\n",
    "                temperature=1,\n",
    "                n=1\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, the revenue projections for next year are as follows:\n",
      "\n",
      "- January: $406,380\n",
      "- February: $488,037\n",
      "- March: $566,877\n",
      "- April: $730,579\n",
      "- May: $834,314\n",
      "- June: $935,740\n",
      "- July: $1,030,004\n",
      "- August: $1,227,245\n",
      "- September: $1,357,593\n",
      "- October: $1,438,669\n",
      "- November: $1,555,585\n",
      "- December: $1,850,950\n",
      "\n",
      "These projections show a steady increase in revenue throughout the year. It is important to note that these figures are estimates and may be subject to change based on market conditions and other factors., Sources: ['vlocker.pdf', 'vlocker.pdf', 'vlocker.pdf']\n"
     ]
    }
   ],
   "source": [
    "answer = get_bplan_response(user_question, context_page_content)\n",
    "\n",
    "print(f\"{answer}, Sources: {[doc[1] for doc in context_list]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=openai.api_key,\n",
    "    model_name='gpt-3.5-turbo-16k-0613',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt():\n",
    "    \"\"\"Create the prompt for the chatbot\"\"\"\n",
    "    template = \"\"\"\n",
    "    You are a master business advisor, advising a client based on\n",
    "    the provided context about their business plan.  If you cannot\n",
    "    find any relevant data in the context, you may offer general \n",
    "    advice, but note that you did not find any relevant context.\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "    qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    return qa_chain_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_prompt = create_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m llm \u001b[39m=\u001b[39m ChatOpenAI(model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m      5\u001b[0m qa_chain \u001b[39m=\u001b[39m RetrievalQA\u001b[39m.\u001b[39mfrom_chain_type(llm,retriever\u001b[39m=\u001b[39mvectorstore\u001b[39m.\u001b[39mas_retriever(),\n\u001b[0;32m      6\u001b[0m chain_type_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: qa_chain_prompt}, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m qa_chain({\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m: question})\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 282\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    283\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    284\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    286\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    270\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    271\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    274\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 276\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    277\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    278\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    279\u001b[0m     )\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:139\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    140\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, question\u001b[39m=\u001b[39;49mquestion, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child()\n\u001b[0;32m    141\u001b[0m )\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n\u001b[0;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer, \u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m: docs}\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:480\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    476\u001b[0m         _output_key\n\u001b[0;32m    477\u001b[0m     ]\n\u001b[0;32m    479\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 480\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    481\u001b[0m         _output_key\n\u001b[0;32m    482\u001b[0m     ]\n\u001b[0;32m    484\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    485\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    486\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 282\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    283\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    284\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    286\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    270\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    271\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    274\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 276\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    277\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    278\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    279\u001b[0m     )\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:105\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    104\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[1;32m--> 105\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_docs(\n\u001b[0;32m    106\u001b[0m     docs, callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mother_keys\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[0;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:171\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs), {}\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\llm.py:255\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    241\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \n\u001b[0;32m    243\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 282\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    283\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    284\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    286\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    270\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    271\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    274\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 276\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    277\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    278\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    279\u001b[0m     )\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\llm.py:91\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     87\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     88\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     89\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     90\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 91\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chains\\llm.py:101\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    102\u001b[0m     prompts,\n\u001b[0;32m    103\u001b[0m     stop,\n\u001b[0;32m    104\u001b[0m     callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs,\n\u001b[0;32m    106\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:414\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    407\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    408\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    412\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    413\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(prompt_messages, stop\u001b[39m=\u001b[39mstop, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[0;32m    308\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 309\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    310\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[0;32m    311\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[0;32m    312\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[0;32m    313\u001b[0m ]\n\u001b[0;32m    314\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:299\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[0;32m    297\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 299\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    300\u001b[0m                 m,\n\u001b[0;32m    301\u001b[0m                 stop\u001b[39m=\u001b[39mstop,\n\u001b[0;32m    302\u001b[0m                 run_manager\u001b[39m=\u001b[39mrun_managers[i] \u001b[39mif\u001b[39;00m run_managers \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    303\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    304\u001b[0m             )\n\u001b[0;32m    305\u001b[0m         )\n\u001b[0;32m    306\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    307\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\base.py:446\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    443\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(\n\u001b[0;32m    447\u001b[0m         messages, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    448\u001b[0m     )\n\u001b[0;32m    449\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\openai.py:339\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    338\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m--> 339\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    340\u001b[0m     messages\u001b[39m=\u001b[39mmessage_dicts, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    341\u001b[0m )\n\u001b[0;32m    342\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\openai.py:278\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 278\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\chat_models\\openai.py:276\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4."
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "question = \"How much do you think we should be asking for in a pre-seed round of financing.\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever(),\n",
    "chain_type_kwargs={\"prompt\": qa_chain_prompt}, verbose=True)\n",
    "qa_chain({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str = Field(description = \"The corrected answer text\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Answer)\n",
    "template = \"Look over this response {response} from a large language model\\\n",
    "      and correct any errors before returning the result as a string.  If there are not\\\n",
    "    specific code examples provided, please add them before returning the result.\\n{format_instructions}\\n{response}\\n\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=[\"response\"], \n",
    "    partial_variables = {\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "gpt_4 = ChatOpenAI(model_name = 'gpt-4-0613', verbose = True, max_retries = 4, max_tokens = 1000)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=gpt_4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.python import PythonREPL\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = ChatOpenAI(temperature=0, model=gpt_4)\n",
    "\n",
    "python = PythonREPL(llm=gpt_4, verbose=True)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"python_repl\",\n",
    "        func=python.run,\n",
    "        description=\"Useful for when you need to write or test python code.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"documentation\",\n",
    "        func=qa.run,\n",
    "        description=\"Useful for when you need to search for documentation, api references, etc.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"format_final_response\",\n",
    "        func=llm_chain.predict_and_parse,\n",
    "        description=\"Useful for when you need to check the final answer for errors and format before\\\n",
    "              returning to the user.\"\n",
    "    )    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrkl = initialize_agent(tools, gpt_4, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'additional_query = \"How can I adjust the pairings functions to be able to generate multiple pairings per recipe,    use redis to manage the pairings and the associated recipes in state, and then use sqalchemy to store the pairings in the bakespace database?    as well as be able to initiate a new chat session with the pairings as context?\"'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_query = f'How can I use the langchain library to create a multi-tool agent\\\n",
    "    that will help farmers find the legal forms they need to fill out in order to start and maintain a farm?\\\n",
    "    I want to use multi-tool agents that can also utilize openai\\'s function capabilities and any other tools\\\n",
    "    that the agent might need to accomplish this task?  I want to use Streamlit to create the interface for the app.'\n",
    "\n",
    "'''additional_query = \"How can I adjust the pairings functions to be able to generate multiple pairings per recipe,\\\n",
    "    use redis to manage the pairings and the associated recipes in state, and then use sqalchemy to store the pairings in the bakespace database?\\\n",
    "    as well as be able to initiate a new chat session with the pairings as context?\"'''\n",
    "\n",
    "#query = base_query + additional_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mBuilding a multi-tool agent to help farmers find the legal forms they need to start and maintain a farm using the langchain library, openai's function capabilities, and Streamlit for the interface involves several steps. Here's a general guide:\n",
      "\n",
      "1. **Understand the Legal Requirements**: First, you need to understand the legal requirements for starting and maintaining a farm. This could vary by location, so you might need to gather data from various legal databases or use APIs that can provide this information.\n",
      "\n",
      "2. **Use Langchain Library**: Langchain is a library that allows you to parse, transform, and analyze legal texts. You can use it to process the legal requirements you gathered in the first step. It can help you identify key phrases and sections that refer to forms that need to be filled out.\n",
      "\n",
      "3. **Leverage openai's Function Capabilities**: Openai's function capabilities can be used to automate the process of searching for and retrieving the necessary forms based on the legal requirements. For example, you could create a function that takes the key phrases identified by Langchain and searches a database or website to find the corresponding forms.\n",
      "\n",
      "4. **Build the Interface with Streamlit**: Streamlit is a great tool for building interactive web applications. You can use it to build the front-end interface for your app. The interface could include a search bar where farmers can input their location and type of farm, and the app would return a list of forms they need to fill out. You could also include links to the forms or instructions on how to fill them out.\n",
      "\n",
      "5. **Combine Everything Together**: Finally, you need to bring all these components together. This could involve writing a main function or script that takes user input from the Streamlit interface, uses the Langchain library and openai's function capabilities to process the input and find the necessary forms, and then returns the results to the user.\n",
      "\n",
      "Here's a pseudo-code example:\n",
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import streamlit as st\n",
      "from langchain import LegalText\n",
      "from openai_functions import find_legal_forms\n",
      "\n",
      "# Define main function\n",
      "def main():\n",
      "    # Get user input from Streamlit interface\n",
      "    location = st.text_input(\"Enter your location:\")\n",
      "    farm_type = st.text_input(\"Enter your type of farm:\")\n",
      "\n",
      "    # Use Langchain to process legal requirements\n",
      "    legal_requirements = get_legal_requirements(location, farm_type)\n",
      "    legal_text = LegalText(legal_requirements)\n",
      "    key_phrases = legal_text.find_key_phrases()\n",
      "\n",
      "    # Use openai's function capabilities to find forms\n",
      "    forms = find_legal_forms(key_phrases)\n",
      "\n",
      "    # Display results in Streamlit interface\n",
      "    st.write(\"Here are the forms you need to fill out:\")\n",
      "    for form in forms:\n",
      "        st.write(form)\n",
      "\n",
      "# Run main function\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "Please note that this is a simplified example and you might need to tweak it depending on the specifics of your project. For example, you might need to add error handling or additional features depending on your needs. Also, you would need to implement the `get_legal_requirements` and `find_legal_forms` functions by yourself, possibly using APIs or scraping techniques. \n",
      "\n",
      "I hope this guide helps you get started with your project! Let me know if you have any other questions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = mrkl.run(base_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a multi-tool agent to help farmers find the legal forms they need to start and maintain a farm using the langchain library, openai's function capabilities, and Streamlit for the interface involves several steps. Here's a general guide:\n",
      "\n",
      "1. **Understand the Legal Requirements**: First, you need to understand the legal requirements for starting and maintaining a farm. This could vary by location, so you might need to gather data from various legal databases or use APIs that can provide this information.\n",
      "\n",
      "2. **Use Langchain Library**: Langchain is a library that allows you to parse, transform, and analyze legal texts. You can use it to process the legal requirements you gathered in the first step. It can help you identify key phrases and sections that refer to forms that need to be filled out.\n",
      "\n",
      "3. **Leverage openai's Function Capabilities**: Openai's function capabilities can be used to automate the process of searching for and retrieving the necessary forms based on the legal requirements. For example, you could create a function that takes the key phrases identified by Langchain and searches a database or website to find the corresponding forms.\n",
      "\n",
      "4. **Build the Interface with Streamlit**: Streamlit is a great tool for building interactive web applications. You can use it to build the front-end interface for your app. The interface could include a search bar where farmers can input their location and type of farm, and the app would return a list of forms they need to fill out. You could also include links to the forms or instructions on how to fill them out.\n",
      "\n",
      "5. **Combine Everything Together**: Finally, you need to bring all these components together. This could involve writing a main function or script that takes user input from the Streamlit interface, uses the Langchain library and openai's function capabilities to process the input and find the necessary forms, and then returns the results to the user.\n",
      "\n",
      "Here's a pseudo-code example:\n",
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import streamlit as st\n",
      "from langchain import LegalText\n",
      "from openai_functions import find_legal_forms\n",
      "\n",
      "# Define main function\n",
      "def main():\n",
      "    # Get user input from Streamlit interface\n",
      "    location = st.text_input(\"Enter your location:\")\n",
      "    farm_type = st.text_input(\"Enter your type of farm:\")\n",
      "\n",
      "    # Use Langchain to process legal requirements\n",
      "    legal_requirements = get_legal_requirements(location, farm_type)\n",
      "    legal_text = LegalText(legal_requirements)\n",
      "    key_phrases = legal_text.find_key_phrases()\n",
      "\n",
      "    # Use openai's function capabilities to find forms\n",
      "    forms = find_legal_forms(key_phrases)\n",
      "\n",
      "    # Display results in Streamlit interface\n",
      "    st.write(\"Here are the forms you need to fill out:\")\n",
      "    for form in forms:\n",
      "        st.write(form)\n",
      "\n",
      "# Run main function\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "Please note that this is a simplified example and you might need to tweak it depending on the specifics of your project. For example, you might need to add error handling or additional features depending on your needs. Also, you would need to implement the `get_legal_requirements` and `find_legal_forms` functions by yourself, possibly using APIs or scraping techniques. \n",
      "\n",
      "I hope this guide helps you get started with your project! Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "session_log_df = pd.read_csv(\"session_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\2262308375.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  session_log_df = session_log_df.append({\"query\": additional_query, \"response\": response}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Add the response and the query to the session log df\n",
    "session_log_df = session_log_df.append({\"query\": additional_query, \"response\": response}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the session log df to a csv\n",
    "session_log_df.to_csv(\"session_log.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n",
      "C:\\Users\\sjufa\\AppData\\Local\\Temp\\ipykernel_28724\\407023106.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  vectors_df = vectors_df.append(vectors, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Loop through the docs and create a vector for each\n",
    "# In the format needed for Pinecone\n",
    "# Create a pandas dataframe with the vectors and metadata\n",
    "\n",
    "# Create the dataframe with the columns \"id\", \"values\", \"metadata\", \"text\"\n",
    "# The \"id\" column should be a unique identifier for each vector\n",
    "# The \"values\" column should be a list of floats\n",
    "# The \"metadata\" column should be a dictionary with keys for \"type\", \"url\", and \"access\"\n",
    "# The \"text\" column should be the text of the document\n",
    "import pandas as pd\n",
    "\n",
    "vectors_df = pd.DataFrame(columns=[\"id\", \"values\", \"metadata\", \"text\"])\n",
    "texts = []\n",
    "for i, doc in enumerate(docs):\n",
    "    text = doc.page_content\n",
    "    source = doc.metadata[\"source\"]\n",
    "    texts.append(text)\n",
    "\n",
    "    # Create the vectors\n",
    "    vectors = [\n",
    "        {'id': f'FastAPI_docs{i}',\n",
    "        'values': [],\n",
    "        'metadata': {'type': 'Github repo docs', 'url': 'https://github.com/tiangolo/fastapi', 'access': 'public', 'text': text, 'source': source},\n",
    "        }\n",
    "    ]\n",
    "    # Add the vectors to the dataframe\n",
    "    vectors_df = vectors_df.append(vectors, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the text column to the dataframe\n",
    "vectors_df[\"text\"] = texts\n",
    "\n",
    "# Embed the texts for the values column\n",
    "vectors_df[\"values\"] = embed.embed_documents(vectors_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Pinecone\n\u001b[1;32m----> 2\u001b[0m index \u001b[39m=\u001b[39m Pinecone\u001b[39m.\u001b[39;49mfrom_documents(docs, embed, index_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvocalockr-bplan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\vectorstores\\base.py:419\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m    418\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m--> 419\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[39m=\u001b[39mmetadatas, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain\\vectorstores\\pinecone.py:353\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, index_name, namespace, upsert_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    349\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import pinecone python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install pinecone-client`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m     )\n\u001b[1;32m--> 353\u001b[0m indexes \u001b[39m=\u001b[39m pinecone\u001b[39m.\u001b[39;49mlist_indexes()  \u001b[39m# checks if provided index exists\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[39mif\u001b[39;00m index_name \u001b[39min\u001b[39;00m indexes:\n\u001b[0;32m    356\u001b[0m     index \u001b[39m=\u001b[39m pinecone\u001b[39m.\u001b[39mIndex(index_name)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\manage.py:185\u001b[0m, in \u001b[0;36mlist_indexes\u001b[1;34m()\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Lists all indexes.\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m api_instance \u001b[39m=\u001b[39m _get_api_instance()\n\u001b[1;32m--> 185\u001b[0m response \u001b[39m=\u001b[39m api_instance\u001b[39m.\u001b[39;49mlist_indexes()\n\u001b[0;32m    186\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:776\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[39m    Example:\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    774\u001b[0m \n\u001b[0;32m    775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 776\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallable(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\api\\index_operations_api.py:1132\u001b[0m, in \u001b[0;36mIndexOperationsApi.__init__.<locals>.__list_indexes\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1129\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m )\n\u001b[0;32m   1131\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1132\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_with_http_info(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:838\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    834\u001b[0m     header_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_client\u001b[39m.\u001b[39mselect_header_content_type(\n\u001b[0;32m    835\u001b[0m         content_type_headers_list)\n\u001b[0;32m    836\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m header_list\n\u001b[1;32m--> 838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[0;32m    839\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mendpoint_path\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mhttp_method\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    840\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    841\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    842\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    843\u001b[0m     body\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    844\u001b[0m     post_params\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mform\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    845\u001b[0m     files\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    846\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mresponse_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    847\u001b[0m     auth_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mauth\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    848\u001b[0m     async_req\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    849\u001b[0m     _check_type\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_check_return_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    850\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    851\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    852\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    853\u001b[0m     _host\u001b[39m=\u001b[39;49m_host,\n\u001b[0;32m    854\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mcollection_format\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:413\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39m    then the method will return the response directly.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[1;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[0;32m    414\u001b[0m                            path_params, query_params, header_params,\n\u001b[0;32m    415\u001b[0m                            body, post_params, files,\n\u001b[0;32m    416\u001b[0m                            response_type, auth_settings,\n\u001b[0;32m    417\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[0;32m    418\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[0;32m    419\u001b[0m                            _check_type)\n\u001b[0;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[0;32m    422\u001b[0m                                                method, path_params,\n\u001b[0;32m    423\u001b[0m                                                query_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                                _request_timeout,\n\u001b[0;32m    432\u001b[0m                                                _host, _check_type))\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:200\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    196\u001b[0m     url \u001b[39m=\u001b[39m _host \u001b[39m+\u001b[39m resource_path\n\u001b[0;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    201\u001b[0m         method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[0;32m    202\u001b[0m         post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    203\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    204\u001b[0m         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[0;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:439\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request using RESTClient.\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mGET(url,\n\u001b[0;32m    440\u001b[0m                                 query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[0;32m    441\u001b[0m                                 _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    442\u001b[0m                                 _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[0;32m    443\u001b[0m                                 headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    444\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mHEAD(url,\n\u001b[0;32m    446\u001b[0m                                  query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[0;32m    447\u001b[0m                                  _preload_content\u001b[39m=\u001b[39m_preload_content,\n\u001b[0;32m    448\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[0;32m    449\u001b[0m                                  headers\u001b[39m=\u001b[39mheaders)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\rest.py:236\u001b[0m, in \u001b[0;36mRESTClientObject.GET\u001b[1;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGET\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    235\u001b[0m         _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[0;32m    237\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    238\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    239\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[0;32m    240\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\pinecone\\core\\client\\rest.py:202\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[39mraise\u001b[39;00m ApiException(status\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, reason\u001b[39m=\u001b[39mmsg)\n\u001b[0;32m    200\u001b[0m     \u001b[39m# For `GET`, `HEAD`\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m         r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool_manager\u001b[39m.\u001b[39;49mrequest(method, url,\n\u001b[0;32m    203\u001b[0m                                       fields\u001b[39m=\u001b[39;49mquery_params,\n\u001b[0;32m    204\u001b[0m                                       preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    205\u001b[0m                                       timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    206\u001b[0m                                       headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m urllib3\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mSSLError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    208\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(e)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\urllib3\\request.py:74\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     71\u001b[0m urlopen_kw[\u001b[39m\"\u001b[39m\u001b[39mrequest_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m url\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_url_methods:\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\urllib3\\request.py:96\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m fields:\n\u001b[0;32m     94\u001b[0m     url \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m urlencode(fields)\n\u001b[1;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, u\u001b[39m.\u001b[39mrequest_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    396\u001b[0m         conn\u001b[39m.\u001b[39mrequest_chunked(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39mrequest(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBrokenPipeError\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (six\u001b[39m.\u001b[39mensure_str(k\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m headers):\n\u001b[0;32m    243\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\http\\client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[0;32m   1281\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1282\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\http\\client.py:1324\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     encode_chunked \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[39mfor\u001b[39;00m hdr, value \u001b[39min\u001b[39;00m headers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m-> 1324\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mputheader(hdr, value)\n\u001b[0;32m   1325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1326\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\site-packages\\urllib3\\connection.py:224\u001b[0m, in \u001b[0;36mHTTPConnection.putheader\u001b[1;34m(self, header, *values)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(v, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m v \u001b[39m==\u001b[39m SKIP_HEADER \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values):\n\u001b[1;32m--> 224\u001b[0m     _HTTPConnection\u001b[39m.\u001b[39;49mputheader(\u001b[39mself\u001b[39;49m, header, \u001b[39m*\u001b[39;49mvalues)\n\u001b[0;32m    225\u001b[0m \u001b[39melif\u001b[39;00m six\u001b[39m.\u001b[39mensure_str(header\u001b[39m.\u001b[39mlower()) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m SKIPPABLE_HEADERS:\n\u001b[0;32m    226\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39murllib3.util.SKIP_HEADER only supports \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mtitle, \u001b[39msorted\u001b[39m(SKIPPABLE_HEADERS))),)\n\u001b[0;32m    229\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sjufa\\anaconda3\\envs\\py310\\lib\\http\\client.py:1260\u001b[0m, in \u001b[0;36mHTTPConnection.putheader\u001b[1;34m(self, header, *values)\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(one_value, \u001b[39mint\u001b[39m):\n\u001b[0;32m   1258\u001b[0m         values[i] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(one_value)\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mascii\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1260\u001b[0m     \u001b[39mif\u001b[39;00m _is_illegal_header_value(values[i]):\n\u001b[0;32m   1261\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid header value \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (values[i],))\n\u001b[0;32m   1263\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(values)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "index = Pinecone.from_documents(docs, embed, index_name=\"vocalockr-bplan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the text column\n",
    "vectors_df = vectors_df.drop(columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a list of dictionaries\n",
    "vectors = vectors_df.to_dict(orient=\"records\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, vector in enumerate(vectors):\n",
    "    if len(vector[\"values\"]) != 1536:\n",
    "        print(i, len(vector[\"values\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_key = os.getenv(\"PINECONE_KEY2\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENV2\")\n",
    "pinecone.init(api_key = pinecone_key, environment=pinecone_env) # Initialize pinecone\n",
    "index = pinecone.Index(index_name=\"coding-assist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf6100c72cd46c58942ea46ecc8d5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 403}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsert the vectors into the vector store\n",
    "index.upsert(vectors=vectors, batch_size=25, namespace=\"documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the vector store\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "index = pinecone.Index('coding-assist')\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = 'gpt-3.5-turbo-16k',\n",
    "    temperature = 0.5,\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = vectorstore.as_retriever(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I use the langchain library to code an app in Streamlit that\\\n",
    "    can be used by farmers to find the forms that they need to fill out to open and\\\n",
    "    run their business based on their location?  I want to use multi-tool agents\\\n",
    "    to accomplish this task.\"\n",
    "\n",
    "response = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have any information about the langchain library or its capabilities. It's possible that the langchain library is a custom library or a library that is not widely known. I recommend referring to the documentation or resources specific to the langchain library for guidance on how to use it for your specific task.\n"
     ]
    }
   ],
   "source": [
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to be able to load YouTube transcripts and create a vector store from them\n",
    "from langchain.document_loaders import YouTubeTranscriptLoader\n",
    "\n",
    "# Create a YouTubeTranscriptLoader object\n",
    "yt_loader = YouTubeTranscriptLoader(\n",
    "    video_id=\"dQw4w9WgXcQ\",\n",
    "    language=\"en\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
